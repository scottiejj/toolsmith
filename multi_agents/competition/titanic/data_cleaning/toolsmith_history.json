[
    {
        "role": "user",
        "content": "You are an excellent toolsmith.\nYou design phase-appropriate tools and their documentation for Planner/Developer to use."
    },
    {
        "role": "user",
        "content": "# TASK\n\nPlease design ML tools for the current development phase: Data Cleaning.\nYour tools should include BOTH:\n1. Dataset-specific tools: Tailored to the unique characteristics of this competition's data\n2. Commonly reusable tools: General-purpose utilities applicable across data science tasks\n\nThe Planner and Developer will use these tools to execute tasks in this phase.\nI will provide you with DATASET BACKGROUND, PHASE CONTEXT, and previous reports and plans.\n\nYou can use the following reasoning pattern to design the tools:\n1. Understand the dataset domain and phase objectives.\n2. Identify dataset-specific needs (e.g., domain-specific transformations, competition-specific patterns)\n3. Identify commonly needed operations for this phase type (e.g., standard EDA plots, generic cleaners)\n4. For each tool, ask yourself and answer:\n    - \"Is this tool dataset-specific or generally reusable?\"\n    - \"What parameters should this tool accept to be flexible?\"\n    - \"Which data types (numerical, categorical, datetime, ID) does this tool handle?\"\n    - \"What are the expected inputs and outputs?\"\n    - \"What constraints or edge cases must the tool handle?\"\n5. Ensure tools are:\n    - Phase-appropriate (EDA tools differ from cleaning or feature engineering tools)\n    - Well-balanced (mix of specific + general utilities)\n    - Well-documented (clear parameter descriptions, applicable situations, and usage notes)\n    - Compliant with README format (JSON schema + Markdown documentation)\n\nDesign as many tools as needed to comprehensively support this phase, but prioritize quality over quantity.\nFocus on tools that will be most useful to the Planner and Developer.\n\n\n# CONSTRAINTS\n\n## CONSTRAINTS ##\n1. Tool Balance:\n   - Design tools appropriate for phase: Data Cleaning\n   - Include BOTH dataset-specific AND commonly reusable tools\n   - Avoid duplicating existing tools (list provided)\n   - Prioritize quality and usefulness over quantity\n   \n2. Technical Requirements:\n   - Use only: pandas, numpy, scikit-learn, scipy, matplotlib, seaborn\n   - No file I/O operations inside tools\n   - No network calls or external dependencies\n   - All tools must be pure functions (no global state modifications)\n\n3. Design Principles:\n   - Parameterize column names (never hard-code feature names)\n   - Provide clear, actionable error messages\n   - Handle edge cases gracefully (empty DataFrames, missing columns, wrong types)\n   - Include type hints for all parameters and return values\n   - Document assumptions and limitations in notes\n   - Mark in description whether tool is \"dataset-specific\" or \"reusable\"\n\n4. Output Requirements:\n   - Each tool MUST have corresponding JSON schema entry\n   - Each tool MUST have markdown documentation\n   - Follow exact README format for both JSON and Markdown\n   - Assign correct category: \"data_cleaning\" | \"feature_engineering\" | \"model_build_predict\"\n\n\n# GUIDELINES\n\n## PHASE-SPECIFIC TOOL GUIDELINES ##\n\n### Preliminary EDA Phase\n- Focus on: exploratory visualization helpers, summary statistic functions, correlation analysis utilities\n- Example tools: multi-feature distribution plotter, automated outlier detector, target-feature relationship analyzer\n\n### Data Cleaning Phase\n- Focus on: missing value handlers, outlier treatment, data type converters, inconsistency fixers\n- Example tools: intelligent missing value imputer (context-aware), categorical encoder with rare category handling, datetime parser with error recovery\n\n### In-depth EDA Phase\n- Focus on: advanced statistical analysis, interaction detection, segmentation helpers\n- Example tools: feature interaction heatmap generator, target stratified analysis, statistical test automation\n\n### Feature Engineering Phase\n- Focus on: transformation utilities, aggregation helpers, domain-specific feature creators\n- Example tools: polynomial/interaction feature generator with auto-selection, time-based feature extractor, target encoding with regularization\n\n### Model Building Phase\n- Focus on: training helpers, evaluation utilities, hyperparameter search wrappers\n- Example tools: cross-validation scorer with multiple metrics, model ensemble builder, prediction calibrator\n\n\n\n## TASK: PRODUCE A COMPLETE PYTHON MODULE OF TOOLS ##\n\nYou are designing tools for the current phase: Data Cleaning.\nUsing the dataset background provided, generate a SINGLE Python module that contains multiple functions.\n\nStrict rules:\n- Follow the style of functions in `ml_tools.py` (clear docstrings: Args, Returns, Raises, Examples when helpful)\n- Use only pandas, numpy, scikit-learn, scipy.stats (standard library allowed); no file/network I/O\n- Pure functions: do not mutate global state; return results explicitly\n- Parameterize column names; no hard-coded feature names\n- Validate inputs and raise ValueError/TypeError with actionable messages\n- Type-hint all parameters and return values\n- Consolidate imports at the top; avoid duplicates\n\nOutput format:\n- Return EXACTLY one fenced Python block containing the entire module content\n- Start with imports, then define all functions\n- One function per tool, snake_case names\n\nModule composition guidance:\n- Include BOTH dataset-specific and reusable tools for the phase\n- Focus on high-utility, phase-appropriate tools\n- Prefer 6\u201312 tools rather than many superficial ones\n\nContext:\nPhase: Data Cleaning\nCompetition: titanic\nDataset Background:\n\n"
    },
    {
        "role": "assistant",
        "content": "```python\nimport pandas as pd\nimport numpy as np\nfrom sklearn.impute import SimpleImputer\nfrom scipy import stats\nimport seaborn as sns\nimport matplotlib.pyplot as plt\n\ndef handle_missing_values(df: pd.DataFrame, column: str, strategy: str = 'mean') -> pd.Series:\n    \"\"\"\n    Handle missing values in a specified column of the DataFrame.\n    \n    Args:\n        df (pd.DataFrame): The input DataFrame.\n        column (str): The column name to handle missing values.\n        strategy (str): The strategy to use for imputation ('mean', 'median', 'most_frequent'). Default is 'mean'.\n        \n    Returns:\n        pd.Series: The column with missing values handled.\n        \n    Raises:\n        ValueError: If the column does not exist in the DataFrame or if an invalid strategy is provided.\n        \n    Example:\n        cleaned_column = handle_missing_values(df, 'Age', strategy='median')\n    \"\"\"\n    if column not in df.columns:\n        raise ValueError(f\"Column '{column}' does not exist in the DataFrame.\")\n    if strategy not in ['mean', 'median', 'most_frequent']:\n        raise ValueError(\"Invalid strategy. Choose from 'mean', 'median', or 'most_frequent'.\")\n        \n    imputer = SimpleImputer(strategy=strategy)\n    df[column] = imputer.fit_transform(df[[column]])\n    return df[column]\n\ndef remove_outliers(df: pd.DataFrame, column: str, threshold: float = 1.5) -> pd.DataFrame:\n    \"\"\"\n    Remove outliers from a specified column using the IQR method.\n    \n    Args:\n        df (pd.DataFrame): The input DataFrame.\n        column (str): The column name to check for outliers.\n        threshold (float): The multiplier for the IQR to define outliers. Default is 1.5.\n        \n    Returns:\n        pd.DataFrame: DataFrame with outliers removed.\n        \n    Raises:\n        ValueError: If the column does not exist in the DataFrame or if it is not numerical.\n        \n    Example:\n        cleaned_df = remove_outliers(df, 'Fare', threshold=1.5)\n    \"\"\"\n    if column not in df.columns:\n        raise ValueError(f\"Column '{column}' does not exist in the DataFrame.\")\n    if not pd.api.types.is_numeric_dtype(df[column]):\n        raise ValueError(f\"Column '{column}' must be numeric to detect outliers.\")\n    \n    q1 = df[column].quantile(0.25)\n    q3 = df[column].quantile(0.75)\n    iqr = q3 - q1\n    lower_bound = q1 - threshold * iqr\n    upper_bound = q3 + threshold * iqr\n    \n    return df[(df[column] >= lower_bound) & (df[column] <= upper_bound)]\n\ndef convert_column_to_datetime(df: pd.DataFrame, column: str, format: str = None) -> pd.Series:\n    \"\"\"\n    Convert a specified column to datetime format.\n    \n    Args:\n        df (pd.DataFrame): The input DataFrame.\n        column (str): The column name to convert.\n        format (str): The format string for datetime conversion. Default is None.\n        \n    Returns:\n        pd.Series: The column converted to datetime.\n        \n    Raises:\n        ValueError: If the column does not exist in the DataFrame.\n        \n    Example:\n        df['Date'] = convert_column_to_datetime(df, 'Date', format='%Y-%m-%d')\n    \"\"\"\n    if column not in df.columns:\n        raise ValueError(f\"Column '{column}' does not exist in the DataFrame.\")\n    \n    df[column] = pd.to_datetime(df[column], format=format, errors='coerce')\n    return df[column]\n\ndef fill_categorical_with_mode(df: pd.DataFrame, column: str) -> pd.Series:\n    \"\"\"\n    Fill missing values in a categorical column with the mode.\n    \n    Args:\n        df (pd.DataFrame): The input DataFrame.\n        column (str): The column name to fill.\n        \n    Returns:\n        pd.Series: The column with missing values filled with the mode.\n        \n    Raises:\n        ValueError: If the column does not exist in the DataFrame or is not categorical.\n        \n    Example:\n        df['Embarked'] = fill_categorical_with_mode(df, 'Embarked')\n    \"\"\"\n    if column not in df.columns:\n        raise ValueError(f\"Column '{column}' does not exist in the DataFrame.\")\n    if not pd.api.types.is_categorical_dtype(df[column]) and not pd.api.types.is_object_dtype(df[column]):\n        raise ValueError(f\"Column '{column}' must be categorical or object type to fill with mode.\")\n    \n    mode = df[column].mode()[0]\n    df[column].fillna(mode, inplace=True)\n    return df[column]\n\ndef plot_missing_data_heatmap(df: pd.DataFrame) -> None:\n    \"\"\"\n    Plot a heatmap of missing data in the DataFrame.\n    \n    Args:\n        df (pd.DataFrame): The input DataFrame.\n        \n    Returns:\n        None: Displays a heatmap of missing values.\n        \n    Example:\n        plot_missing_data_heatmap(df)\n    \"\"\"\n    plt.figure(figsize=(10, 6))\n    sns.heatmap(df.isnull(), cbar=False, cmap='viridis')\n    plt.title('Missing Data Heatmap')\n    plt.show()\n\ndef standardize_column(df: pd.DataFrame, column: str) -> pd.Series:\n    \"\"\"\n    Standardize a specified numerical column to have a mean of 0 and standard deviation of 1.\n    \n    Args:\n        df (pd.DataFrame): The input DataFrame.\n        column (str): The column name to standardize.\n        \n    Returns:\n        pd.Series: The standardized column.\n        \n    Raises:\n        ValueError: If the column does not exist in the DataFrame or is not numerical.\n        \n    Example:\n        df['Fare'] = standardize_column(df, 'Fare')\n    \"\"\"\n    if column not in df.columns:\n        raise ValueError(f\"Column '{column}' does not exist in the DataFrame.\")\n    if not pd.api.types.is_numeric_dtype(df[column]):\n        raise ValueError(f\"Column '{column}' must be numeric to standardize.\")\n    \n    df[column] = (df[column] - df[column].mean()) / df[column].std()\n    return df[column]\n\ndef encode_categorical(df: pd.DataFrame, column: str) -> pd.DataFrame:\n    \"\"\"\n    Encode a categorical column into numerical format using one-hot encoding.\n    \n    Args:\n        df (pd.DataFrame): The input DataFrame.\n        column (str): The column name to encode.\n        \n    Returns:\n        pd.DataFrame: The DataFrame with the encoded column.\n        \n    Raises:\n        ValueError: If the column does not exist in the DataFrame.\n        \n    Example:\n        df_encoded = encode_categorical(df, 'Embarked')\n    \"\"\"\n    if column not in df.columns:\n        raise ValueError(f\"Column '{column}' does not exist in the DataFrame.\")\n    \n    df_encoded = pd.get_dummies(df, columns=[column], drop_first=True)\n    return df_encoded\n\ndef fix_inconsistent_categories(df: pd.DataFrame, column: str, inconsistent_values: dict) -> pd.Series:\n    \"\"\"\n    Fix inconsistent categories in a specified categorical column.\n    \n    Args:\n        df (pd.DataFrame): The input DataFrame.\n        column (str): The column name to fix.\n        inconsistent_values (dict): A dictionary mapping inconsistent values to the correct value.\n        \n    Returns:\n        pd.Series: The column with fixed categories.\n        \n    Raises:\n        ValueError: If the column does not exist in the DataFrame.\n        \n    Example:\n        df['Cabin'] = fix_inconsistent_categories(df, 'Cabin', {'C': 'C1', 'C2': 'C1'})\n    \"\"\"\n    if column not in df.columns:\n        raise ValueError(f\"Column '{column}' does not exist in the DataFrame.\")\n    \n    df[column].replace(inconsistent_values, inplace=True)\n    return df[column]\n```\n"
    },
    {
        "role": "user",
        "content": "\n## TASK: CONVERT PYTHON TOOLS TO MARKDOWN DOCS ##\n\nYou will receive a complete Python module containing multiple tool functions.\nFor EACH top-level function, produce a markdown section that follows the EXACT format of PROMPT_TOOLSMITH_MARKDOWN_FORMAT.\n\nRules:\n- Use the function name as the tool name\n- Derive parameter info and types from the function signature and docstring\n- Keep the formatting EXACT (labels, backticks, enums, separators) per the spec\n- Output ONLY one concatenated fenced block: ```markdown\\n...sections...\\n```\n- Do not include any prose before or after the fenced block.\n\nREFERENCE FORMAT (do not reproduce here, just follow it):\n\n## REQUIRED MARKDOWN FORMAT ##\nFor each tool, produce EXACT markdown following this structure:\n\n## <tool_name>\n\n**Name:** <tool_name>  \n**Description:** <one-sentence or short paragraph description>  \n**Applicable Situations:** <short phrase describing when to use this tool>\n\n**Parameters:**\n- `<param_name>`:\n  - **Type:** `<type>` (e.g., `pd.DataFrame`, ``string` | `array``, `number`, `boolean`)\n  - **Description:** <clear parameter description>\n  - **Enum:** `value1` | `value2` | `value3`  (ONLY include this line if enum exists)\n  - **Default:** `<value>` or `None`  (ONLY include this line if default exists)\n\n(Repeat the above parameter block for each parameter)\n\n**Required:** `param1`, `param2`  (or write `None` if no required parameters)\n**Result:** <one-sentence description of the successful outcome>  \n**Notes:**\n- <explanatory note 1>\n- <explanatory note 2>\n- <explanatory note 3>\n(Add as many notes as needed to explain assumptions, limitations, edge cases, or best practices)\n\n---\n\nIMPORTANT FORMATTING RULES:\n1. Use exactly two spaces after each colon in bold labels (e.g., \"**Name:**  \")\n2. Parameter type uses backticks with pipes for unions: ``string` | `array``\n3. Enum values separated by ` | ` (space-pipe-space) with backticks around each value\n4. Default values use backticks: `None`, `0.5`, `'auto'`\n5. End each tool section with \"---\" separator (three dashes)\n6. Required parameters listed as comma-separated with backticks: `param1`, `param2`\n7. Notes are bullet points, each starting with \"- \"\n\nExample of correct formatting:\n\n## fill_missing_values\n\n**Name:** fill_missing_values  \n**Description:** Fill missing values in specified columns of a DataFrame. This tool can handle both numerical and categorical features by using different filling methods.  \n**Applicable Situations:** handle missing values in various types of features\n\n**Parameters:**\n- `data`:\n  - **Type:** `pd.DataFrame`\n  - **Description:** A pandas DataFrame object representing the dataset.\n- `columns`:\n  - **Type:** ``string` | `array``\n  - **Description:** The name(s) of the column(s) where missing values should be filled.\n- `method`:\n  - **Type:** `string`\n  - **Description:** The method to use for filling missing values.\n  - **Enum:** `auto` | `mean` | `median` | `mode` | `constant`\n  - **Default:** `auto`\n- `fill_value`:\n  - **Type:** ``number` | `string` | `null``\n  - **Description:** The value to use when method is 'constant'.\n  - **Default:** `None`\n\n**Required:** `data`, `columns`  \n**Result:** Successfully fill missing values in the specified column(s) of data  \n**Notes:**\n- The 'auto' method uses mean for numeric columns and mode for non-numeric columns.\n- Using 'mean' or 'median' on non-numeric columns will raise an error.\n- The 'mode' method uses the most frequent value, which may not always be appropriate.\n- Filling missing values can introduce bias, especially if the data is not missing completely at random.\n- Consider the impact of filling missing values on your analysis and model performance.\n\n---\n\n\n\nHere is the MARKDOWN format you should follow (example):\n```markdown\n## fill_missing_values\n\n**Name:** fill_missing_values  \n**Description:** Fill missing values in specified columns of a DataFrame. This tool can handle both numerical and categorical features by using different filling methods.  \n**Applicable Situations:** handle missing values in various types of features\n\n**Parameters:**\n- `data`:\n  - **Type:** `pd.DataFrame`\n  - **Description:** A pandas DataFrame object representing the dataset.\n- `columns`:\n  - **Type:** ``string` | `array``\n  - **Description:** The name(s) of the column(s) where missing values should be filled.\n- `method`:\n  - **Type:** `string`\n  - **Description:** The method to use for filling missing values.\n  - **Enum:** `auto` | `mean` | `median` | `mode` | `constant`\n  - **Default:** `auto`\n- `fill_value`:\n  - **Type:** ``number` | `string` | `null``\n  - **Description:** The value to use when method is 'constant'.\n  - **Default:** `None`\n\n**Required:** `data`, `columns`  \n**Result:** Successfully fill missing values in the specified column(s) of data  \n**Notes:**\n- The 'auto' method uses mean for numeric columns and mode for non-numeric columns.\n- Using 'mean' or 'median' on non-numeric columns will raise an error.\n- The 'mode' method uses the most frequent value, which may not always be appropriate.\n- Filling missing values can introduce bias, especially if the data is not missing completely at random.\n- Consider the impact of filling missing values on your analysis and model performance.\n\n---\n```\n\nPYTHON MODULE SOURCE:\nimport pandas as pd\nimport numpy as np\nfrom sklearn.impute import SimpleImputer\nfrom scipy import stats\nimport seaborn as sns\nimport matplotlib.pyplot as plt\n\ndef handle_missing_values(df: pd.DataFrame, column: str, strategy: str = 'mean') -> pd.Series:\n    \"\"\"\n    Handle missing values in a specified column of the DataFrame.\n    \n    Args:\n        df (pd.DataFrame): The input DataFrame.\n        column (str): The column name to handle missing values.\n        strategy (str): The strategy to use for imputation ('mean', 'median', 'most_frequent'). Default is 'mean'.\n        \n    Returns:\n        pd.Series: The column with missing values handled.\n        \n    Raises:\n        ValueError: If the column does not exist in the DataFrame or if an invalid strategy is provided.\n        \n    Example:\n        cleaned_column = handle_missing_values(df, 'Age', strategy='median')\n    \"\"\"\n    if column not in df.columns:\n        raise ValueError(f\"Column '{column}' does not exist in the DataFrame.\")\n    if strategy not in ['mean', 'median', 'most_frequent']:\n        raise ValueError(\"Invalid strategy. Choose from 'mean', 'median', or 'most_frequent'.\")\n        \n    imputer = SimpleImputer(strategy=strategy)\n    df[column] = imputer.fit_transform(df[[column]])\n    return df[column]\n\ndef remove_outliers(df: pd.DataFrame, column: str, threshold: float = 1.5) -> pd.DataFrame:\n    \"\"\"\n    Remove outliers from a specified column using the IQR method.\n    \n    Args:\n        df (pd.DataFrame): The input DataFrame.\n        column (str): The column name to check for outliers.\n        threshold (float): The multiplier for the IQR to define outliers. Default is 1.5.\n        \n    Returns:\n        pd.DataFrame: DataFrame with outliers removed.\n        \n    Raises:\n        ValueError: If the column does not exist in the DataFrame or if it is not numerical.\n        \n    Example:\n        cleaned_df = remove_outliers(df, 'Fare', threshold=1.5)\n    \"\"\"\n    if column not in df.columns:\n        raise ValueError(f\"Column '{column}' does not exist in the DataFrame.\")\n    if not pd.api.types.is_numeric_dtype(df[column]):\n        raise ValueError(f\"Column '{column}' must be numeric to detect outliers.\")\n    \n    q1 = df[column].quantile(0.25)\n    q3 = df[column].quantile(0.75)\n    iqr = q3 - q1\n    lower_bound = q1 - threshold * iqr\n    upper_bound = q3 + threshold * iqr\n    \n    return df[(df[column] >= lower_bound) & (df[column] <= upper_bound)]\n\ndef convert_column_to_datetime(df: pd.DataFrame, column: str, format: str = None) -> pd.Series:\n    \"\"\"\n    Convert a specified column to datetime format.\n    \n    Args:\n        df (pd.DataFrame): The input DataFrame.\n        column (str): The column name to convert.\n        format (str): The format string for datetime conversion. Default is None.\n        \n    Returns:\n        pd.Series: The column converted to datetime.\n        \n    Raises:\n        ValueError: If the column does not exist in the DataFrame.\n        \n    Example:\n        df['Date'] = convert_column_to_datetime(df, 'Date', format='%Y-%m-%d')\n    \"\"\"\n    if column not in df.columns:\n        raise ValueError(f\"Column '{column}' does not exist in the DataFrame.\")\n    \n    df[column] = pd.to_datetime(df[column], format=format, errors='coerce')\n    return df[column]\n\ndef fill_categorical_with_mode(df: pd.DataFrame, column: str) -> pd.Series:\n    \"\"\"\n    Fill missing values in a categorical column with the mode.\n    \n    Args:\n        df (pd.DataFrame): The input DataFrame.\n        column (str): The column name to fill.\n        \n    Returns:\n        pd.Series: The column with missing values filled with the mode.\n        \n    Raises:\n        ValueError: If the column does not exist in the DataFrame or is not categorical.\n        \n    Example:\n        df['Embarked'] = fill_categorical_with_mode(df, 'Embarked')\n    \"\"\"\n    if column not in df.columns:\n        raise ValueError(f\"Column '{column}' does not exist in the DataFrame.\")\n    if not pd.api.types.is_categorical_dtype(df[column]) and not pd.api.types.is_object_dtype(df[column]):\n        raise ValueError(f\"Column '{column}' must be categorical or object type to fill with mode.\")\n    \n    mode = df[column].mode()[0]\n    df[column].fillna(mode, inplace=True)\n    return df[column]\n\ndef plot_missing_data_heatmap(df: pd.DataFrame) -> None:\n    \"\"\"\n    Plot a heatmap of missing data in the DataFrame.\n    \n    Args:\n        df (pd.DataFrame): The input DataFrame.\n        \n    Returns:\n        None: Displays a heatmap of missing values.\n        \n    Example:\n        plot_missing_data_heatmap(df)\n    \"\"\"\n    plt.figure(figsize=(10, 6))\n    sns.heatmap(df.isnull(), cbar=False, cmap='viridis')\n    plt.title('Missing Data Heatmap')\n    plt.show()\n\ndef standardize_column(df: pd.DataFrame, column: str) -> pd.Series:\n    \"\"\"\n    Standardize a specified numerical column to have a mean of 0 and standard deviation of 1.\n    \n    Args:\n        df (pd.DataFrame): The input DataFrame.\n        column (str): The column name to standardize.\n        \n    Returns:\n        pd.Series: The standardized column.\n        \n    Raises:\n        ValueError: If the column does not exist in the DataFrame or is not numerical.\n        \n    Example:\n        df['Fare'] = standardize_column(df, 'Fare')\n    \"\"\"\n    if column not in df.columns:\n        raise ValueError(f\"Column '{column}' does not exist in the DataFrame.\")\n    if not pd.api.types.is_numeric_dtype(df[column]):\n        raise ValueError(f\"Column '{column}' must be numeric to standardize.\")\n    \n    df[column] = (df[column] - df[column].mean()) / df[column].std()\n    return df[column]\n\ndef encode_categorical(df: pd.DataFrame, column: str) -> pd.DataFrame:\n    \"\"\"\n    Encode a categorical column into numerical format using one-hot encoding.\n    \n    Args:\n        df (pd.DataFrame): The input DataFrame.\n        column (str): The column name to encode.\n        \n    Returns:\n        pd.DataFrame: The DataFrame with the encoded column.\n        \n    Raises:\n        ValueError: If the column does not exist in the DataFrame.\n        \n    Example:\n        df_encoded = encode_categorical(df, 'Embarked')\n    \"\"\"\n    if column not in df.columns:\n        raise ValueError(f\"Column '{column}' does not exist in the DataFrame.\")\n    \n    df_encoded = pd.get_dummies(df, columns=[column], drop_first=True)\n    return df_encoded\n\ndef fix_inconsistent_categories(df: pd.DataFrame, column: str, inconsistent_values: dict) -> pd.Series:\n    \"\"\"\n    Fix inconsistent categories in a specified categorical column.\n    \n    Args:\n        df (pd.DataFrame): The input DataFrame.\n        column (str): The column name to fix.\n        inconsistent_values (dict): A dictionary mapping inconsistent values to the correct value.\n        \n    Returns:\n        pd.Series: The column with fixed categories.\n        \n    Raises:\n        ValueError: If the column does not exist in the DataFrame.\n        \n    Example:\n        df['Cabin'] = fix_inconsistent_categories(df, 'Cabin', {'C': 'C1', 'C2': 'C1'})\n    \"\"\"\n    if column not in df.columns:\n        raise ValueError(f\"Column '{column}' does not exist in the DataFrame.\")\n    \n    df[column].replace(inconsistent_values, inplace=True)\n    return df[column]\n"
    },
    {
        "role": "assistant",
        "content": "```markdown\n## handle_missing_values\n\n**Name:** handle_missing_values  \n**Description:** Handle missing values in a specified column of the DataFrame.  \n**Applicable Situations:** fill missing values in a specific column\n\n**Parameters:**\n- `df`:\n  - **Type:** `pd.DataFrame`\n  - **Description:** The input DataFrame.\n- `column`:\n  - **Type:** `string`\n  - **Description:** The column name to handle missing values.\n- `strategy`:\n  - **Type:** `string`\n  - **Description:** The strategy to use for imputation.\n  - **Enum:** `mean` | `median` | `most_frequent`\n  - **Default:** `mean`\n\n**Required:** `df`, `column`  \n**Result:** Successfully handle missing values in the specified column  \n**Notes:**\n- If the column does not exist, a ValueError is raised.\n- The strategy must be one of the specified options.\n- The imputation method will modify the DataFrame in place.\n\n---\n\n## remove_outliers\n\n**Name:** remove_outliers  \n**Description:** Remove outliers from a specified column using the IQR method.  \n**Applicable Situations:** clean data by eliminating outliers from a numerical feature\n\n**Parameters:**\n- `df`:\n  - **Type:** `pd.DataFrame`\n  - **Description:** The input DataFrame.\n- `column`:\n  - **Type:** `string`\n  - **Description:** The column name to check for outliers.\n- `threshold`:\n  - **Type:** `float`\n  - **Description:** The multiplier for the IQR to define outliers.\n  - **Default:** `1.5`\n\n**Required:** `df`, `column`  \n**Result:** DataFrame with outliers removed from the specified column  \n**Notes:**\n- If the column does not exist or is not numerical, a ValueError is raised.\n- Outliers are defined as points beyond the lower and upper bounds calculated from the IQR.\n\n---\n\n## convert_column_to_datetime\n\n**Name:** convert_column_to_datetime  \n**Description:** Convert a specified column to datetime format.  \n**Applicable Situations:** convert string dates to datetime objects for analysis\n\n**Parameters:**\n- `df`:\n  - **Type:** `pd.DataFrame`\n  - **Description:** The input DataFrame.\n- `column`:\n  - **Type:** `string`\n  - **Description:** The column name to convert.\n- `format`:\n  - **Type:** `string`\n  - **Description:** The format string for datetime conversion.\n  - **Default:** `None`\n\n**Required:** `df`, `column`  \n**Result:** Successfully convert the specified column to datetime format  \n**Notes:**\n- If the column does not exist, a ValueError is raised.\n- Invalid date formats will be coerced to NaT (Not a Time).\n\n---\n\n## fill_categorical_with_mode\n\n**Name:** fill_categorical_with_mode  \n**Description:** Fill missing values in a categorical column with the mode.  \n**Applicable Situations:** handle missing values in categorical features\n\n**Parameters:**\n- `df`:\n  - **Type:** `pd.DataFrame`\n  - **Description:** The input DataFrame.\n- `column`:\n  - **Type:** `string`\n  - **Description:** The column name to fill.\n\n**Required:** `df`, `column`  \n**Result:** Column with missing values filled with the mode  \n**Notes:**\n- If the column does not exist or is not categorical, a ValueError is raised.\n- The mode is calculated based on the most frequent value in the column.\n\n---\n\n## plot_missing_data_heatmap\n\n**Name:** plot_missing_data_heatmap  \n**Description:** Plot a heatmap of missing data in the DataFrame.  \n**Applicable Situations:** visualize the distribution of missing values in the dataset\n\n**Parameters:**\n- `df`:\n  - **Type:** `pd.DataFrame`\n  - **Description:** The input DataFrame.\n\n**Required:** `df`  \n**Result:** Displays a heatmap of missing values  \n**Notes:**\n- This function does not return any value; it directly plots the heatmap.\n- Ensure that the DataFrame is not empty to avoid plotting errors.\n\n---\n\n## standardize_column\n\n**Name:** standardize_column  \n**Description:** Standardize a specified numerical column to have a mean of 0 and standard deviation of 1.  \n**Applicable Situations:** prepare numerical features for modeling by standardizing\n\n**Parameters:**\n- `df`:\n  - **Type:** `pd.DataFrame`\n  - **Description:** The input DataFrame.\n- `column`:\n  - **Type:** `string`\n  - **Description:** The column name to standardize.\n\n**Required:** `df`, `column`  \n**Result:** The standardized column  \n**Notes:**\n- If the column does not exist or is not numerical, a ValueError is raised.\n- Standardization modifies the DataFrame in place.\n\n---\n\n## encode_categorical\n\n**Name:** encode_categorical  \n**Description:** Encode a categorical column into numerical format using one-hot encoding.  \n**Applicable Situations:** convert categorical features into a usable format for modeling\n\n**Parameters:**\n- `df`:\n  - **Type:** `pd.DataFrame`\n  - **Description:** The input DataFrame.\n- `column`:\n  - **Type:** `string`\n  - **Description:** The column name to encode.\n\n**Required:** `df`, `column`  \n**Result:** DataFrame with the encoded column  \n**Notes:**\n- If the column does not exist, a ValueError is raised.\n- One-hot encoding will drop the first category to avoid multicollinearity.\n\n---\n\n## fix_inconsistent_categories\n\n**Name:** fix_inconsistent_categories  \n**Description:** Fix inconsistent categories in a specified categorical column.  \n**Applicable Situations:** standardize categorical values to ensure consistency\n\n**Parameters:**\n- `df`:\n  - **Type:** `pd.DataFrame`\n  - **Description:** The input DataFrame.\n- `column`:\n  - **Type:** `string`\n  - **Description:** The column name to fix.\n- `inconsistent_values`:\n  - **Type:** `dict`\n  - **Description:** A dictionary mapping inconsistent values to the correct value.\n\n**Required:** `df`, `column`, `inconsistent_values`  \n**Result:** The column with fixed categories  \n**Notes:**\n- If the column does not exist, a ValueError is raised.\n- Inconsistent values will be replaced in the DataFrame in place.\n```"
    }
]