[
    {
        "role": "system",
        "content": "You are an excellent toolsmith.\nYou design phase-appropriate tools and their documentation for Planner/Developer to use."
    },
    {
        "role": "user",
        "content": "# INITIAL DATASET BACKGROUND\nYour ultimate goal is to design tools for the dataset described below (initial background):\n# Competition Information\n\n## 1. Competition Overview\nThe \"obesity_risks\" competition is a part of the Kaggle Playground Series, focusing on predicting obesity risk in individuals related to cardiovascular diseases. The competition runs from February 1, 2024, to March 1, 2024, and submissions are evaluated based on accuracy.\n\n## 2. Files\n- **train.csv**: The training dataset containing features and the target variable `NObeyesdad`.\n- **test.csv**: The test dataset for which predictions need to be made.\n- **sample_submission.csv**: A template to demonstrate the required submission format.\n\n## 3. Problem Definition\nParticipants are tasked with predicting the obesity classification of individuals based on various demographic and lifestyle features. The target variable `NObeyesdad` categorizes individuals into different obesity risk levels.\n\n## 4. Data Information\n### 4.1 Data type\n#### 4.1.1 ID type\n- `id`: Unique identifier for each data point (not used in model training).\n\n#### 4.1.2 Numerical type\n- `Age`: Age of individuals (in years).\n- `Height`: Height of individuals (in meters).\n- `Weight`: Weight of individuals (in kilograms).\n- `CH2O`: Daily water intake (liters).\n- `FAF`: Frequency of physical activity.\n- `TUE`: Time spent exercising (in hours).\n- `CALC`: Daily calcium intake (grams).\n\n#### 4.1.3 Categorical type\n- `Gender`: Gender of individuals (Male/Female).\n- `family_history_with_overweight`: Family history of overweight (yes/no).\n- `FAVC`: Food intake frequency (yes/no).\n- `FCVC`: Frequency of vegetable consumption (numerical scale).\n- `NCP`: Number of meals consumed per day (numerical scale).\n- `CAEC`: Consumption of food between meals (categorical).\n- `SMOKE`: Smoking status (yes/no).\n- `SCC`: Self-calculated calories (yes/no).\n- `MTRANS`: Means of transportation (categorical).\n- `NObeyesdad`: Level of obesity (target variable).\n\n#### 4.1.4 Datetime type\n- None.\n\n### 4.2 Detailed data description\nThe dataset consists of training and test segments, capturing demographic and lifestyle information. The target variable `NObeyesdad` classifies individuals into obesity levels ranging from \"Insufficient Weight\" to \"Obesity Type III.\" The training data includes various age groups, height and weight variations, and lifestyle behaviors.\n\n## 5. Target Variable\nThe target variable `NObeyesdad` categorizes obesity levels into the following classes:\n- \"Insufficient Weight\"\n- \"Normal Weight\"\n- \"Overweight Level I\"\n- \"Overweight Level II\"\n- \"Obesity Type I\"\n- \"Obesity Type II\"\n- \"Obesity Type III\"\n\n## 6. Evaluation Metrics\nSubmissions will be evaluated based on the accuracy score, which measures the proportion of correctly predicted classifications.\n\n## 7. Submission Format\nThe submission file must include the following columns:\n- `id`: Unique identifier for each data point.\n- `NObeyesdad`: Predicted obesity classification.\n\nAn example submission format:\n```\nid,NObeyesdad\n20758,Normal_Weight\n20759,Normal_Weight\n20760,Obesity Type I\n```\n\n## 8. Other Key Aspects\n- The competition utilizes a synthetically generated dataset, allowing for a balance between real-world data characteristics and confidentiality of test labels.\n- Participants are encouraged to explore data visualizations, clustering, and exploratory data analysis (EDA) as part of their solutions.\n- Prizes consist of Kaggle merchandise, with limitations on multiple wins by the same individual.\n\n# TASK\n\nYou are now designing ML tools for the current development phase: Preliminary Exploratory Data Analysis.\nYour tools should include BOTH:\n1. Dataset-specific tools: Tailored to the unique characteristics of this dataset\n2. Commonly reusable tools: General-purpose utilities applicable across data science tasks\n\nThe Planner and Developer will use these tools to execute tasks in this phase.\nI will provide you with DATASET BACKGROUND, PHASE Information, and previous reports and plans.\n\nYou can use the following reasoning pattern to design the tools:\n1. Understand the dataset domain and phase objectives.\n2. Identify dataset-specific needs (e.g., domain-specific transformations, dataset-specific patterns)\n3. Identify commonly needed operations for this phase type (e.g., standard EDA plots, generic cleaners)\n4. For each tool, ask yourself and answer:\n    - \"Is this tool dataset-specific or generally reusable?\"\n    - \"What parameters should this tool accept to be flexible?\"\n    - \"Which data types (numerical, categorical, datetime, ID) does this tool handle?\"\n    - \"What are the expected inputs and outputs?\"\n    - \"What constraints or edge cases must the tool handle?\"\n5. Ensure tools are:\n    - Phase-appropriate (EDA tools differ from cleaning or feature engineering tools)\n    - Well-balanced (mix of specific + general utilities)\n    - Well-documented (clear parameter descriptions, applicable situations, and usage notes)\n    - Compliant with README format (Markdown documentation)\n\nDesign as many tools as needed to comprehensively support this phase, but prioritize quality over quantity.\nFocus on tools that will be most useful to the Planner and Developer.\n\nImportant: Strongly prioritize domain-specific (dataset background-aware) tools whenever they provide clear value. Make their domain rationale explicit so users understand why they are beneficial for this dataset.\n\n\n# CONSTRAINTS\n\n## CONSTRAINTS ##\n1. Tool Balance:\n   - Design tools appropriate for phase: Preliminary Exploratory Data Analysis\n   - Include BOTH dataset-specific AND generic data science tools\n   - Prioritize dataset-specific tools when they add measurable value (keep a healthy mix)\n   - Prioritize quality and usefulness over quantity\n   \n2. Technical Requirements:\n   - Use only: pandas, numpy, scikit-learn, scipy, matplotlib, seaborn\n   - No file I/O operations inside tools\n   - No network calls or external dependencies\n   - All tools must be pure functions (no global state modifications)\n\n3. Design Principles:\n   - Parameterize column names (never hard-code feature names)\n   - Provide clear, actionable error messages\n   - Handle edge cases gracefully (empty DataFrames, missing columns, wrong types)\n   - Include type hints for all parameters and return values\n   - Document assumptions and limitations in notes\n   - Mark in description whether tool is \"dataset-specific\" or \"generic\"\n   - For dataset-specific tools, include a brief \"Domain rationale\" note explaining why the tool fits this dataset background\n\n4. Output Requirements:\n   - Each tool MUST have markdown documentation\n   - Follow exact README format for Markdown\n\n\n#############\n# START TOOL DESIGN #\nBefore you begin, please request the following information from me, which contain important information that will guide your tool design for current phase:\n0. CURRENT phase specific tool GUIDELINES\n1. CURRENT phase available features\n2. CURRENT phase data preview\n3. Previous phases' plans and reports\n"
    },
    {
        "role": "assistant",
        "content": "Thank you! To ensure I design the most effective tools for the Preliminary Exploratory Data Analysis (EDA) phase, please provide the following:\n\n0. **CURRENT phase specific tool GUIDELINES**\n   - Any guidelines, requirements, or preferences for the types of EDA to perform at this stage (e.g., focus on distributions, outlier detection, correlation, etc.)\n\n1. **CURRENT phase available features**\n   - A list of all features (columns) currently present in the dataset, including any known data types or value ranges if available.\n\n2. **CURRENT phase data preview**\n   - A sample (head) of the data for both train and test sets, if possible (a few rows and/or summary statistics).\n\n3. **Previous phases' plans and reports**\n   - Any relevant context or decisions made in earlier phases that should inform tool design for this EDA phase.\n\nWith this information, I can tailor both dataset-specific and general-purpose EDA tools to fit your exact needs."
    },
    {
        "role": "user",
        "content": "\n## TASK: PRODUCE A COMPLETE PYTHON MODULE OF TOOLS ##\n\nYou are designing tools for the current phase: Preliminary Exploratory Data Analysis.\n## PHASE-SPECIFIC TOOL GUIDELINES ##:\n\n- Focus on: exploratory visualization helpers, summary statistic functions, correlation analysis utilities, plus dataset background-aware diagnostics\n- Example tools: multi-feature distribution plotter, automated outlier detector, target-feature relationship analyzer, domain-specific checks derived from dataset background\n- Visualization tools MUST NOT display figures (no `plt.show()`). They should return the plot object (figure/axes) for the caller to save.\n\n\nUsing the Context provided below, generate a SINGLE Python module that contains multiple functions.\n\nStrict rules:\n- Follow the style of functions in `ml_tools.py` (clear docstrings: Args, Returns, Raises, Examples when helpful)\n- Use only pandas, numpy, scikit-learn, scipy.stats (standard library allowed); no file/network I/O\n- Pure functions: do not mutate global state; return results explicitly\n- Parameterize column names; no hard-coded feature names\n- Validate inputs and raise ValueError/TypeError with actionable messages\n- Type-hint all parameters and return values\n- Consolidate imports at the top; avoid duplicates\n - For the Model Building phase specifically: include at least three `scikit-learn` model wrappers with a common interface (`fit_and_evaluate_<algo>`), and document an explicit standardized Return schema (keys for metrics, `cv_scores`, `model_name`, `estimator`).\n\nOutput format:\n- Return EXACTLY one fenced Python block containing the entire module content\n- Start with imports, then define all functions\n- One function per tool, snake_case names\n- Define and use consistent, unambiguous key names in returned dicts and DataFrame columns; avoid synonyms. Include an explicit \"Return schema\" in the docstring listing exact keys and types.\n\n\nModule composition guidance:\n- Include BOTH dataset-specific and reusable tools for the phase\n- Focus on high-utility, phase-appropriate tools\n - Prefer LESS THAN 10 tools rather than many superficial ones\n- Prefer domain-specific (dataset background-aware) tools where they provide clear benefit; include a brief \"Domain rationale\" in each such function's docstring or notes\n\nContext:\nPhase: Preliminary Exploratory Data Analysis\nCompetition: obesity_risks\nCURRENT phase available features:\n\n#############\n# TARGET VARIABLE #\n['NObeyesdad']\n#############\n# TRAIN DATA WITH FEATURES #\nid,Gender,Age,Height,Weight,family_history_with_overweight,FAVC,FCVC,NCP,CAEC,SMOKE,CH2O,SCC,FAF,TUE,CALC,MTRANS,NObeyesdad\n\n#############\n# TEST DATA WITH FEATURES #\nid,Gender,Age,Height,Weight,family_history_with_overweight,FAVC,FCVC,NCP,CAEC,SMOKE,CH2O,SCC,FAF,TUE,CALC,MTRANS\n\nCURRENT phase data preview:\nData preview:\n# Data Information\n\n## Data Type\n\n### ID type\n- `id`: Unique identifier for each data point (NOT used for model training).\n\n### Numerical type\n- `Age`: Age of the individual (float).\n- `Height`: Height in meters (float).\n- `Weight`: Weight in kilograms (float).\n- `FCVC`: Frequency of consumption of vegetables (float).\n- `NCP`: Number of main meals (float).\n- `CH2O`: Daily water consumption (float).\n- `FAF`: Physical activity frequency (float; hours per week or similar unit).\n- `TUE`: Time using technology devices (float; hours per day or similar unit).\n\n### Categorical type\n- `Gender`: Male/Female.\n- `family_history_with_overweight`: yes/no.\n- `FAVC`: Frequent consumption of high caloric food (yes/no).\n- `CAEC`: Consumption of food between meals (Sometimes/Frequently/Always/no).\n- `SMOKE`: Smoking habit (yes/no).\n- `SCC`: Monitoring of caloric consumption (yes/no).\n- `CALC`: Consumption of alcohol (Sometimes/Frequently/Always/no).\n- `MTRANS`: Transportation used (Public_Transportation/Automobile/etc.).\n- `NObeyesdad`: Obesity level/type (target variable; e.g., Obesity_Type_II, Normal_Weight, etc.).\n\n### Datetime type\n- None present in this dataset.\n\n## Detailed data description\n\nThe dataset contains information related to demographic, lifestyle, and behavioral factors that may influence body weight and obesity. Each data point represents an individual and includes:\n\n- **Demographics:** Gender, Age.\n- **Anthropometrics:** Height, Weight.\n- **Family History:** Information about family history of overweight.\n- **Dietary Habits:** Frequency of high caloric food, vegetable consumption, number of meals, water intake, snacking habits.\n- **Lifestyle:** Smoking, alcohol consumption, physical activity, time spent on technology, use of caloric monitoring, and transportation means.\n\n**Notable patterns and characteristics:**\n- Most categorical features are 'yes/no' or have limited options (e.g., Sometimes/Frequently/Always/no).\n- Numerical features are continuous and may require normalization.\n- The target variable (`NObeyesdad`) is multi-class, indicating different levels and types of obesity or normal/insufficient weight.\n- No datetime or time-series features are present.\n- The data may include outliers (e.g., high weights or heights) and missing values appear unlikely from the sample provided.\n\n## Target Variable\n\n- **Target:** `NObeyesdad`\n- **Description:** Categorical variable indicating the obesity weight status of the individual. Example classes include:\n    - Insufficient_Weight\n    - Normal_Weight\n    - Overweight_Level_I\n    - Overweight_Level_II\n    - Obesity_Type_I\n    - Obesity_Type_II\n    - Obesity_Type_III\n\n## Submission format (if applicable)\n\nThe submission file should contain:\n- `id`: Unique identifier for each individual (integer).\n- `NObeyesdad`: Predicted obesity class for each individual (string; one of the classes as in the target variable).\n\n**Example:**\n| id    | NObeyesdad         |\n|-------|--------------------|\n| 20758 | Obesity_Type_II    |\n| 20759 | Normal_Weight      |\n| ...   | ...                |\n\n- Types: `id` (integer), `NObeyesdad` (string/category)\nPrevious Plans and Reports:\n## UNDERSTAND BACKGROUND ##\nThere is no plan in this phase.\n\nThere is no report in the previous phase.\n\n\n\n\n"
    },
    {
        "role": "assistant",
        "content": "```python\nimport pandas as pd\nimport numpy as np\nfrom typing import List, Tuple, Dict, Optional, Union\nimport matplotlib.pyplot as plt\nimport seaborn as sns\nfrom scipy import stats\n\n#########################\n# PRELIMINARY EDA TOOLS #\n#########################\n\ndef summarize_categorical_features(\n    df: pd.DataFrame,\n    categorical_cols: List[str]\n) -> pd.DataFrame:\n    \"\"\"\n    Summarizes categorical columns: unique values, value counts, and missing values.\n    \n    Dataset-specific or Generic: Generic\n\n    Args:\n        df (pd.DataFrame): The data frame containing the data.\n        categorical_cols (List[str]): List of column names to summarize.\n\n    Returns:\n        pd.DataFrame: Summary table with columns: 'feature', 'num_unique', 'most_common', 'most_common_freq', 'missing_count'.\n\n    Raises:\n        ValueError: If any of the categorical columns are missing in the DataFrame.\n\n    Example:\n        >>> summarize_categorical_features(df, ['Gender', 'SMOKE'])\n    \"\"\"\n    missing = [col for col in categorical_cols if col not in df.columns]\n    if missing:\n        raise ValueError(f\"Columns not found in DataFrame: {missing}\")\n    summary = []\n    for col in categorical_cols:\n        vc = df[col].value_counts(dropna=False)\n        most_common = vc.index[0] if not vc.empty else np.nan\n        most_common_freq = vc.iloc[0] if not vc.empty else 0\n        summary.append({\n            'feature': col,\n            'num_unique': df[col].nunique(dropna=True),\n            'most_common': most_common,\n            'most_common_freq': most_common_freq,\n            'missing_count': df[col].isnull().sum()\n        })\n    return pd.DataFrame(summary)\n\ndef summarize_numerical_features(\n    df: pd.DataFrame,\n    numerical_cols: List[str]\n) -> pd.DataFrame:\n    \"\"\"\n    Provides descriptive statistics for numerical columns.\n    \n    Dataset-specific or Generic: Generic\n\n    Args:\n        df (pd.DataFrame): The data frame containing the data.\n        numerical_cols (List[str]): List of numerical column names.\n\n    Returns:\n        pd.DataFrame: Descriptive statistics table with columns: 'feature', 'mean', 'std', 'min', '25%', '50%', '75%', 'max', 'missing_count'.\n\n    Raises:\n        ValueError: If any of the numerical columns are missing in the DataFrame.\n\n    Example:\n        >>> summarize_numerical_features(df, ['Age', 'Height'])\n    \"\"\"\n    missing = [col for col in numerical_cols if col not in df.columns]\n    if missing:\n        raise ValueError(f\"Columns not found in DataFrame: {missing}\")\n    desc = df[numerical_cols].describe().T\n    desc['missing_count'] = df[numerical_cols].isnull().sum()\n    columns = ['mean', 'std', 'min', '25%', '50%', '75%', 'max', 'missing_count']\n    desc = desc.rename_axis('feature').reset_index()\n    return desc[['feature'] + [c for c in columns if c in desc.columns]]\n\ndef plot_numerical_distributions(\n    df: pd.DataFrame,\n    numerical_cols: List[str],\n    target_col: Optional[str] = None,\n    n_cols: int = 3,\n    figsize: Tuple[int, int] = (16, 4)\n) -> plt.Figure:\n    \"\"\"\n    Plots histograms (optionally colored by target class) for multiple numerical features.\n\n    Dataset-specific or Generic: Generic\n\n    Args:\n        df (pd.DataFrame): DataFrame with data.\n        numerical_cols (List[str]): List of numerical features to plot.\n        target_col (Optional[str]): If provided, use as hue for color separation.\n        n_cols (int): Number of columns in subplot grid.\n        figsize (Tuple[int, int]): Figure size.\n\n    Returns:\n        plt.Figure: The matplotlib Figure object (not shown).\n\n    Raises:\n        ValueError: If any numerical columns are missing.\n\n    Example:\n        >>> fig = plot_numerical_distributions(df, ['Age', 'Weight'], target_col='NObeyesdad')\n    \"\"\"\n    missing = [col for col in numerical_cols if col not in df.columns]\n    if missing:\n        raise ValueError(f\"Columns not found in DataFrame: {missing}\")\n    n = len(numerical_cols)\n    n_rows = (n + n_cols - 1) // n_cols\n    fig, axs = plt.subplots(n_rows, n_cols, figsize=(figsize[0], figsize[1]*n_rows))\n    axs = axs.flatten()\n    for i, col in enumerate(numerical_cols):\n        ax = axs[i]\n        if target_col and target_col in df.columns:\n            sns.histplot(data=df, x=col, hue=target_col, multiple='stack', ax=ax, kde=False)\n        else:\n            sns.histplot(df[col].dropna(), ax=ax, kde=True)\n        ax.set_title(col)\n    # Remove unused subplots\n    for j in range(i+1, len(axs)):\n        fig.delaxes(axs[j])\n    fig.tight_layout()\n    return fig\n\ndef plot_categorical_counts(\n    df: pd.DataFrame,\n    categorical_cols: List[str],\n    target_col: Optional[str] = None,\n    n_cols: int = 3,\n    figsize: Tuple[int, int] = (16, 4)\n) -> plt.Figure:\n    \"\"\"\n    Plots countplots for multiple categorical features (optionally colored by target class).\n\n    Dataset-specific or Generic: Generic\n\n    Args:\n        df (pd.DataFrame): DataFrame with data.\n        categorical_cols (List[str]): Categorical features to plot.\n        target_col (Optional[str]): Target column for hue grouping.\n        n_cols (int): Number of columns in subplot grid.\n        figsize (Tuple[int, int]): Figure size.\n\n    Returns:\n        plt.Figure: The matplotlib Figure object (not shown).\n\n    Raises:\n        ValueError: If any categorical columns are missing.\n\n    Example:\n        >>> fig = plot_categorical_counts(df, ['Gender', 'SMOKE'], target_col='NObeyesdad')\n    \"\"\"\n    missing = [col for col in categorical_cols if col not in df.columns]\n    if missing:\n        raise ValueError(f\"Columns not found in DataFrame: {missing}\")\n    n = len(categorical_cols)\n    n_rows = (n + n_cols - 1) // n_cols\n    fig, axs = plt.subplots(n_rows, n_cols, figsize=(figsize[0], figsize[1]*n_rows))\n    axs = axs.flatten()\n    for i, col in enumerate(categorical_cols):\n        ax = axs[i]\n        if target_col and target_col in df.columns:\n            sns.countplot(data=df, x=col, hue=target_col, ax=ax)\n        else:\n            sns.countplot(data=df, x=col, ax=ax)\n        ax.set_title(col)\n        ax.legend(loc='best', fontsize='small') if target_col else None\n    for j in range(i+1, len(axs)):\n        fig.delaxes(axs[j])\n    fig.tight_layout()\n    return fig\n\ndef analyze_target_distribution(\n    df: pd.DataFrame,\n    target_col: str\n) -> pd.DataFrame:\n    \"\"\"\n    Analyzes the class distribution of the target variable.\n\n    Dataset-specific or Generic: Dataset-specific\n\n    Domain rationale:\n        The dataset's target is a multi-class categorical variable (\"NObeyesdad\") with potentially imbalanced classes.\n        Understanding class distribution is crucial for modeling and evaluation.\n\n    Args:\n        df (pd.DataFrame): DataFrame with target column.\n        target_col (str): The target column name.\n\n    Returns:\n        pd.DataFrame: Table with 'class', 'count', 'proportion'.\n\n    Raises:\n        ValueError: If target_col is missing.\n\n    Example:\n        >>> analyze_target_distribution(df, 'NObeyesdad')\n    \"\"\"\n    if target_col not in df.columns:\n        raise ValueError(f\"Target column '{target_col}' not found in DataFrame.\")\n    vc = df[target_col].value_counts(dropna=False)\n    total = len(df)\n    result = pd.DataFrame({\n        'class': vc.index,\n        'count': vc.values,\n        'proportion': vc.values / total\n    })\n    return result\n\ndef correlation_matrix_heatmap(\n    df: pd.DataFrame,\n    numerical_cols: List[str],\n    method: str = \"pearson\",\n    figsize: Tuple[int, int] = (10, 8)\n) -> plt.Figure:\n    \"\"\"\n    Plots a correlation matrix heatmap for numerical features.\n\n    Dataset-specific or Generic: Generic\n\n    Args:\n        df (pd.DataFrame): DataFrame.\n        numerical_cols (List[str]): List of numerical columns to include.\n        method (str): Correlation method ('pearson', 'spearman', 'kendall').\n        figsize (Tuple[int, int]): Figure size.\n\n    Returns:\n        plt.Figure: The matplotlib Figure object (not shown).\n\n    Raises:\n        ValueError: If any numerical columns are missing or method is invalid.\n\n    Example:\n        >>> fig = correlation_matrix_heatmap(df, ['Age', 'Height', 'Weight'])\n    \"\"\"\n    missing = [col for col in numerical_cols if col not in df.columns]\n    if missing:\n        raise ValueError(f\"Columns not found in DataFrame: {missing}\")\n    if method not in ['pearson', 'spearman', 'kendall']:\n        raise ValueError(\"method must be one of: 'pearson', 'spearman', 'kendall'\")\n    corr = df[numerical_cols].corr(method=method)\n    fig, ax = plt.subplots(figsize=figsize)\n    sns.heatmap(corr, annot=True, fmt=\".2f\", cmap='coolwarm', ax=ax)\n    ax.set_title(f\"{method.title()} Correlation Matrix\")\n    return fig\n\ndef bmi_feature_analysis(\n    df: pd.DataFrame,\n    height_col: str,\n    weight_col: str,\n    target_col: Optional[str] = None\n) -> Dict[str, Union[pd.Series, plt.Figure]]:\n    \"\"\"\n    Computes BMI (Body Mass Index) for each individual, summarizes its distribution, and optionally visualizes by target class.\n\n    Dataset-specific or Generic: Dataset-specific\n\n    Domain rationale:\n        BMI is a primary indicator for obesity risk, directly related to the prediction target.\n        Assessing its distribution and its relation to \"NObeyesdad\" provides critical insights.\n\n    Args:\n        df (pd.DataFrame): Input DataFrame.\n        height_col (str): Column for height (meters).\n        weight_col (str): Column for weight (kg).\n        target_col (Optional[str]): If provided, produces a plot colored by this column.\n\n    Returns:\n        Dict[str, Union[pd.Series, plt.Figure]]:\n            {\n                'bmi_series': pd.Series (BMI values, indexed as df),\n                'bmi_summary': pd.Series (basic statistics),\n                'bmi_plot': plt.Figure (if target_col provided, else None)\n            }\n\n    Raises:\n        ValueError: If columns are missing or contain invalid (<=0) values.\n\n    Example:\n        >>> result = bmi_feature_analysis(df, 'Height', 'Weight', target_col='NObeyesdad')\n        >>> result['bmi_series']\n        >>> result['bmi_summary']\n        >>> fig = result['bmi_plot']\n    \"\"\"\n    for col in [height_col, weight_col]:\n        if col not in df.columns:\n            raise ValueError(f\"Column '{col}' not found in DataFrame.\")\n    # Avoid division by zero or negative values\n    height = df[height_col].astype(float)\n    weight = df[weight_col].astype(float)\n    if (height <= 0).any():\n        raise ValueError(\"All height values must be positive and non-zero.\")\n    bmi = weight / (height ** 2)\n    bmi_summary = bmi.describe()\n    fig = None\n    if target_col and target_col in df.columns:\n        fig, ax = plt.subplots(figsize=(8,5))\n        sns.histplot(data=df.assign(BMI=bmi), x='BMI', hue=target_col, multiple='stack', kde=True, ax=ax)\n        ax.set_title('BMI Distribution by ' + target_col)\n    return {\n        'bmi_series': bmi,\n        'bmi_summary': bmi_summary,\n        'bmi_plot': fig\n    }\n\ndef automated_outlier_detector(\n    df: pd.DataFrame,\n    numerical_cols: List[str],\n    method: str = \"iqr\",\n    threshold: float = 1.5\n) -> pd.DataFrame:\n    \"\"\"\n    Identifies outliers in numerical columns using IQR or z-score method.\n\n    Dataset-specific or Generic: Generic\n\n    Args:\n        df (pd.DataFrame): DataFrame to check.\n        numerical_cols (List[str]): List of numerical columns to check.\n        method (str): 'iqr' or 'zscore'.\n        threshold (float): Outlier threshold (IQR multiple or z-score).\n\n    Returns:\n        pd.DataFrame: Table with columns: 'feature', 'outlier_count', 'outlier_ratio', 'method', 'threshold'.\n\n    Raises:\n        ValueError: If any columns are missing, or method invalid.\n\n    Example:\n        >>> automated_outlier_detector(df, ['Age', 'Weight'])\n    \"\"\"\n    missing = [col for col in numerical_cols if col not in df.columns]\n    if missing:\n        raise ValueError(f\"Columns not found in DataFrame: {missing}\")\n    if method not in [\"iqr\", \"zscore\"]:\n        raise ValueError(\"method must be 'iqr' or 'zscore'\")\n    results = []\n    for col in numerical_cols:\n        series = df[col].dropna()\n        if method == \"iqr\":\n            Q1 = series.quantile(0.25)\n            Q3 = series.quantile(0.75)\n            IQR = Q3 - Q1\n            lower = Q1 - threshold * IQR\n            upper = Q3 + threshold * IQR\n            mask = (series < lower) | (series > upper)\n        else:  # zscore\n            mean = series.mean()\n            std = series.std()\n            if std == 0:\n                mask = pd.Series([False]*len(series), index=series.index)\n            else:\n                zscores = (series - mean) / std\n                mask = (zscores < -threshold) | (zscores > threshold)\n        outlier_count = mask.sum()\n        results.append({\n            'feature': col,\n            'outlier_count': int(outlier_count),\n            'outlier_ratio': float(outlier_count) / len(series) if len(series) > 0 else np.nan,\n            'method': method,\n            'threshold': threshold\n        })\n    return pd.DataFrame(results)\n\ndef target_feature_impact_analysis(\n    df: pd.DataFrame,\n    feature_cols: List[str],\n    target_col: str,\n    feature_types: Optional[Dict[str, str]] = None\n) -> pd.DataFrame:\n    \"\"\"\n    Quantifies the association between features and the target.\n    For numerical features: computes ANOVA F-statistic and p-value.\n    For categorical features: computes Cram\u00e9r's V.\n\n    Dataset-specific or Generic: Dataset-specific\n\n    Domain rationale:\n        The target is multi-class categorical, so understanding which features (diet, lifestyle, etc.)\n        show the strongest association with obesity risk is critical for both feature selection and interpretation.\n\n    Args:\n        df (pd.DataFrame): DataFrame.\n        feature_cols (List[str]): Features to analyze.\n        target_col (str): The target variable (must be categorical).\n        feature_types (Optional[Dict[str, str]]): Dict mapping feature name to 'categorical' or 'numerical'.\n                                                 If None, types are inferred.\n\n    Returns:\n        pd.DataFrame: Table with columns:\n            'feature', 'feature_type', 'association', 'p_value' (for numerical), 'method'\n\n    Raises:\n        ValueError: If columns are missing.\n\n    Example:\n        >>> target_feature_impact_analysis(df, ['Age', 'Gender', 'FAF'], 'NObeyesdad')\n    \"\"\"\n    if target_col not in df.columns:\n        raise ValueError(f\"Target column '{target_col}' not found.\")\n    missing = [col for col in feature_cols if col not in df.columns]\n    if missing:\n        raise ValueError(f\"Feature columns not found: {missing}\")\n    # Infer types if not provided\n    inferred_types = {}\n    for col in feature_cols:\n        if feature_types and col in feature_types:\n            inferred_types[col] = feature_types[col]\n        else:\n            # Heuristic: object or category = categorical, else numerical\n            dtype = df[col].dtype\n            if pd.api.types.is_numeric_dtype(dtype):\n                inferred_types[col] = 'numerical'\n            else:\n                inferred_types[col] = 'categorical'\n    results = []\n    for col in feature_cols:\n        ftype = inferred_types[col]\n        if ftype == 'numerical':\n            # One-way ANOVA F-test\n            groups = [df[df[target_col]==cls][col].dropna() for cls in df[target_col].unique()]\n            if any(len(g)==0 for g in groups):\n                # If any class is empty, skip\n                association, pval = np.nan, np.nan\n            else:\n                association, pval = stats.f_oneway(*groups)\n            method = 'ANOVA F-stat'\n        else:\n            # Categorical: Cram\u00e9r's V\n            confusion = pd.crosstab(df[col], df[target_col])\n            chi2 = stats.chi2_contingency(confusion, correction=False)[0]\n            n = confusion.sum().sum()\n            k = min(confusion.shape)  # min(num categories, num classes)\n            # Avoid divide by zero\n            cramers_v = np.sqrt(chi2 / (n * (k-1))) if k > 1 and n > 0 else np.nan\n            association, pval = cramers_v, np.nan\n            method = \"Cram\u00e9r's V\"\n        results.append({\n            'feature': col,\n            'feature_type': ftype,\n            'association': association,\n            'p_value': pval,\n            'method': method\n        })\n    return pd.DataFrame(results)\n\ndef feature_vs_target_boxplot(\n    df: pd.DataFrame,\n    numerical_col: str,\n    target_col: str,\n    figsize: Tuple[int, int] = (8,5)\n) -> plt.Figure:\n    \"\"\"\n    Boxplot of a numerical feature grouped by target classes.\n\n    Dataset-specific or Generic: Dataset-specific\n\n    Domain rationale:\n        For this dataset, visualizing how BMI, Age, Weight, or other numerics vary by obesity class can reveal\n        separable patterns and inform feature engineering.\n\n    Args:\n        df (pd.DataFrame): DataFrame.\n        numerical_col (str): Feature to plot.\n        target_col (str): Target variable.\n\n    Returns:\n        plt.Figure: The matplotlib Figure object.\n\n    Raises:\n        ValueError: If columns are missing.\n\n    Example:\n        >>> fig = feature_vs_target_boxplot(df, 'Age', 'NObeyesdad')\n    \"\"\"\n    for col in [numerical_col, target_col]:\n        if col not in df.columns:\n            raise ValueError(f\"Column '{col}' not found in DataFrame.\")\n    fig, ax = plt.subplots(figsize=figsize)\n    sns.boxplot(x=target_col, y=numerical_col, data=df, ax=ax)\n    ax.set_xticklabels(ax.get_xticklabels(), rotation=30, ha='right')\n    ax.set_title(f'{numerical_col} by {target_col}')\n    return fig\n\n####################\n# END OF MODULE    #\n####################\n```"
    },
    {
        "role": "user",
        "content": "\n## TASK: CONVERT PYTHON TOOLS TO MARKDOWN DOCS ##\n\nYou will receive a complete Python module containing multiple tool functions.\n\nRules:\n- Use the function name as the tool name\n- Derive parameter info and types from the function signature and docstring\n- Keep the formatting EXACT (labels, backticks, enums, separators) per the spec\n- Output ONLY one concatenated fenced block: ```markdown\\n...sections...\\n```\n- Do not include any prose before or after the fenced block.\n- If a function is dataset-specific, include a note line in the Notes section starting with \"- Domain rationale:\" that briefly explains why the tool is suited to this dataset/competition\n\n\nFor EACH top-level function, produce a markdown section that follows the EXACT format of the example below.\n\nHere is the MARKDOWN format you should follow (example):\n```markdown\n## fill_missing_values\n\n**Name:** fill_missing_values  \n**Description:** Fill missing values in specified columns of a DataFrame. This tool can handle both numerical and categorical features by using different filling methods.  \n**Applicable Situations:** handle missing values in various types of features\n\n**Parameters:**\n- `data`:\n  - **Type:** `pd.DataFrame`\n  - **Description:** A pandas DataFrame object representing the dataset.\n- `columns`:\n  - **Type:** ``string` | `array``\n  - **Description:** The name(s) of the column(s) where missing values should be filled.\n- `method`:\n  - **Type:** `string`\n  - **Description:** The method to use for filling missing values.\n  - **Enum:** `auto` | `mean` | `median` | `mode` | `constant`\n  - **Default:** `auto`\n- `fill_value`:\n  - **Type:** ``number` | `string` | `null``\n  - **Description:** The value to use when method is 'constant'.\n  - **Default:** `None`\n\n**Required:** `data`, `columns`  \n**Result:** Successfully fill missing values in the specified column(s) of data  \n**Notes:**\n- The 'auto' method uses mean for numeric columns and mode for non-numeric columns.\n- Using 'mean' or 'median' on non-numeric columns will raise an error.\n- The 'mode' method uses the most frequent value, which may not always be appropriate.\n- Filling missing values can introduce bias, especially if the data is not missing completely at random.\n- Consider the impact of filling missing values on your analysis and model performance.\n\n---\n```\n\nPYTHON MODULE SOURCE:\n{python_source}\n"
    },
    {
        "role": "assistant",
        "content": "```markdown\n## summarize_categorical_features\n\n**Name:** summarize_categorical_features  \n**Description:** Summarizes categorical columns: unique values, value counts, and missing values.  \n**Applicable Situations:** Get an overview of categorical distributions, class balance, and missing data in categorical features.\n\n**Parameters:**\n- `df`:\n  - **Type:** `pd.DataFrame`\n  - **Description:** The data frame containing the data.\n- `categorical_cols`:\n  - **Type:** `List[str]`\n  - **Description:** List of column names to summarize.\n\n**Required:** `df`, `categorical_cols`  \n**Result:** Summary table with columns: 'feature', 'num_unique', 'most_common', 'most_common_freq', 'missing_count'  \n**Notes:**\n- Raises ValueError if any specified categorical columns are missing.\n- Useful before encoding or further processing categorical variables.\n\n---\n\n## summarize_numerical_features\n\n**Name:** summarize_numerical_features  \n**Description:** Provides descriptive statistics for numerical columns.  \n**Applicable Situations:** Quickly assess range, central tendency, spread, and missingness in numerical data.\n\n**Parameters:**\n- `df`:\n  - **Type:** `pd.DataFrame`\n  - **Description:** The data frame containing the data.\n- `numerical_cols`:\n  - **Type:** `List[str]`\n  - **Description:** List of numerical column names.\n\n**Required:** `df`, `numerical_cols`  \n**Result:** Descriptive statistics table with columns: 'feature', 'mean', 'std', 'min', '25%', '50%', '75%', 'max', 'missing_count'  \n**Notes:**\n- Raises ValueError if any specified numerical columns are missing.\n- Use this to detect likely outliers or data entry errors.\n\n---\n\n## plot_numerical_distributions\n\n**Name:** plot_numerical_distributions  \n**Description:** Plots histograms (optionally colored by target class) for multiple numerical features.  \n**Applicable Situations:** Visualize the distribution of multiple numeric features, optionally stratified by a categorical target.\n\n**Parameters:**\n- `df`:\n  - **Type:** `pd.DataFrame`\n  - **Description:** DataFrame with data.\n- `numerical_cols`:\n  - **Type:** `List[str]`\n  - **Description:** List of numerical features to plot.\n- `target_col`:\n  - **Type:** `Optional[str]`\n  - **Description:** If provided, use as hue for color separation.\n  - **Default:** `None`\n- `n_cols`:\n  - **Type:** `int`\n  - **Description:** Number of columns in subplot grid.\n  - **Default:** `3`\n- `figsize`:\n  - **Type:** `Tuple[int, int]`\n  - **Description:** Figure size (width, height).\n  - **Default:** `(16, 4)`\n\n**Required:** `df`, `numerical_cols`  \n**Result:** The matplotlib Figure object (not shown).  \n**Notes:**\n- Raises ValueError if any numerical columns are missing.\n- Returns the figure object for further processing or saving.\n\n---\n\n## plot_categorical_counts\n\n**Name:** plot_categorical_counts  \n**Description:** Plots countplots for multiple categorical features (optionally colored by target class).  \n**Applicable Situations:** Visualize the frequency of categories, optionally by class, to check for imbalance or patterns.\n\n**Parameters:**\n- `df`:\n  - **Type:** `pd.DataFrame`\n  - **Description:** DataFrame with data.\n- `categorical_cols`:\n  - **Type:** `List[str]`\n  - **Description:** Categorical features to plot.\n- `target_col`:\n  - **Type:** `Optional[str]`\n  - **Description:** Target column for hue grouping.\n  - **Default:** `None`\n- `n_cols`:\n  - **Type:** `int`\n  - **Description:** Number of columns in subplot grid.\n  - **Default:** `3`\n- `figsize`:\n  - **Type:** `Tuple[int, int]`\n  - **Description:** Figure size (width, height).\n  - **Default:** `(16, 4)`\n\n**Required:** `df`, `categorical_cols`  \n**Result:** The matplotlib Figure object (not shown).  \n**Notes:**\n- Raises ValueError if any categorical columns are missing.\n- Returns the figure object for further processing or saving.\n\n---\n\n## analyze_target_distribution\n\n**Name:** analyze_target_distribution  \n**Description:** Analyzes the class distribution of the target variable.  \n**Applicable Situations:** Assess class balance/imbalance in the target variable for impact on modeling and metric choice.\n\n**Parameters:**\n- `df`:\n  - **Type:** `pd.DataFrame`\n  - **Description:** DataFrame with target column.\n- `target_col`:\n  - **Type:** `str`\n  - **Description:** The target column name.\n\n**Required:** `df`, `target_col`  \n**Result:** Table with 'class', 'count', 'proportion'.  \n**Notes:**\n- Raises ValueError if the target column is missing.\n- - Domain rationale: The dataset's target is a multi-class categorical variable (\"NObeyesdad\") with potentially imbalanced classes. Understanding class distribution is crucial for modeling and evaluation.\n\n---\n\n## correlation_matrix_heatmap\n\n**Name:** correlation_matrix_heatmap  \n**Description:** Plots a correlation matrix heatmap for numerical features.  \n**Applicable Situations:** Visualize linear (or rank-based) relationships among numerical features to detect multicollinearity or clusters.\n\n**Parameters:**\n- `df`:\n  - **Type:** `pd.DataFrame`\n  - **Description:** DataFrame.\n- `numerical_cols`:\n  - **Type:** `List[str]`\n  - **Description:** List of numerical columns to include.\n- `method`:\n  - **Type:** `str`\n  - **Description:** Correlation method.\n  - **Enum:** `pearson` | `spearman` | `kendall`\n  - **Default:** `pearson`\n- `figsize`:\n  - **Type:** `Tuple[int, int]`\n  - **Description:** Figure size (width, height).\n  - **Default:** `(10, 8)`\n\n**Required:** `df`, `numerical_cols`  \n**Result:** The matplotlib Figure object (not shown).  \n**Notes:**\n- Raises ValueError if any numerical columns are missing or method is invalid.\n- Returns the figure object for further processing or saving.\n\n---\n\n## bmi_feature_analysis\n\n**Name:** bmi_feature_analysis  \n**Description:** Computes BMI (Body Mass Index) for each individual, summarizes its distribution, and optionally visualizes by target class.  \n**Applicable Situations:** Directly assess a core medical risk factor (BMI) distribution and its relation to obesity classes.\n\n**Parameters:**\n- `df`:\n  - **Type:** `pd.DataFrame`\n  - **Description:** Input DataFrame.\n- `height_col`:\n  - **Type:** `str`\n  - **Description:** Column for height (meters).\n- `weight_col`:\n  - **Type:** `str`\n  - **Description:** Column for weight (kg).\n- `target_col`:\n  - **Type:** `Optional[str]`\n  - **Description:** If provided, produces a plot colored by this column.\n  - **Default:** `None`\n\n**Required:** `df`, `height_col`, `weight_col`  \n**Result:** Dict with keys:\n  - 'bmi_series': pd.Series (BMI values, indexed as df)\n  - 'bmi_summary': pd.Series (basic statistics)\n  - 'bmi_plot': plt.Figure (if target_col provided, else None)  \n**Notes:**\n- Raises ValueError if columns are missing or contain invalid (<=0) values.\n- - Domain rationale: BMI is a primary indicator for obesity risk, directly related to the prediction target. Assessing its distribution and its relation to \"NObeyesdad\" provides critical insights.\n\n---\n\n## automated_outlier_detector\n\n**Name:** automated_outlier_detector  \n**Description:** Identifies outliers in numerical columns using IQR or z-score method.  \n**Applicable Situations:** Automated detection and quantification of potential anomalous values in continuous data.\n\n**Parameters:**\n- `df`:\n  - **Type:** `pd.DataFrame`\n  - **Description:** DataFrame to check.\n- `numerical_cols`:\n  - **Type:** `List[str]`\n  - **Description:** List of numerical columns to check.\n- `method`:\n  - **Type:** `str`\n  - **Description:** Outlier detection method.\n  - **Enum:** `iqr` | `zscore`\n  - **Default:** `iqr`\n- `threshold`:\n  - **Type:** `float`\n  - **Description:** Outlier threshold (IQR multiple or z-score).\n  - **Default:** `1.5`\n\n**Required:** `df`, `numerical_cols`  \n**Result:** Table with columns: 'feature', 'outlier_count', 'outlier_ratio', 'method', 'threshold'.  \n**Notes:**\n- Raises ValueError if any columns are missing, or method invalid.\n- Use high thresholds for robust detection, or lower to flag more points.\n\n---\n\n## target_feature_impact_analysis\n\n**Name:** target_feature_impact_analysis  \n**Description:** Quantifies the association between features and the target. For numerical features: computes ANOVA F-statistic and p-value. For categorical features: computes Cram\u00e9r's V.  \n**Applicable Situations:** Identify which features (numerical or categorical) are most associated with the multi-class target for feature selection or interpretation.\n\n**Parameters:**\n- `df`:\n  - **Type:** `pd.DataFrame`\n  - **Description:** DataFrame.\n- `feature_cols`:\n  - **Type:** `List[str]`\n  - **Description:** Features to analyze.\n- `target_col`:\n  - **Type:** `str`\n  - **Description:** The target variable (must be categorical).\n- `feature_types`:\n  - **Type:** `Optional[Dict[str, str]]`\n  - **Description:** Dict mapping feature name to 'categorical' or 'numerical'. If None, types are inferred.\n  - **Default:** `None`\n\n**Required:** `df`, `feature_cols`, `target_col`  \n**Result:** Table with columns: 'feature', 'feature_type', 'association', 'p_value' (for numerical), 'method'  \n**Notes:**\n- Raises ValueError if columns are missing.\n- - Domain rationale: The target is multi-class categorical, so understanding which features (diet, lifestyle, etc.) show the strongest association with obesity risk is critical for both feature selection and interpretation.\n\n---\n\n## feature_vs_target_boxplot\n\n**Name:** feature_vs_target_boxplot  \n**Description:** Boxplot of a numerical feature grouped by target classes.  \n**Applicable Situations:** Visualize spread and central tendency of a numeric feature across obesity classes.\n\n**Parameters:**\n- `df`:\n  - **Type:** `pd.DataFrame`\n  - **Description:** DataFrame.\n- `numerical_col`:\n  - **Type:** `str`\n  - **Description:** Feature to plot.\n- `target_col`:\n  - **Type:** `str`\n  - **Description:** Target variable.\n- `figsize`:\n  - **Type:** `Tuple[int, int]`\n  - **Description:** Figure size (width, height).\n  - **Default:** `(8, 5)`\n\n**Required:** `df`, `numerical_col`, `target_col`  \n**Result:** The matplotlib Figure object.  \n**Notes:**\n- Raises ValueError if columns are missing.\n- - Domain rationale: For this dataset, visualizing how BMI, Age, Weight, or other numerics vary by obesity class can reveal separable patterns and inform feature engineering.\n\n---\n```"
    }
]