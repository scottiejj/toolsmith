[
    {
        "role": "system",
        "content": "You are an excellent toolsmith.\nYou design phase-appropriate tools and their documentation for Planner/Developer to use."
    },
    {
        "role": "user",
        "content": "# INITIAL DATASET BACKGROUND\nYour ultimate goal is to design tools for the dataset described below (initial background):\n# Competition Information\n\n## 1. Competition Overview\nThe \"obesity_risks\" competition is a part of the Kaggle Playground Series, focusing on predicting obesity risk in individuals related to cardiovascular diseases. The competition runs from February 1, 2024, to March 1, 2024, and submissions are evaluated based on accuracy.\n\n## 2. Files\n- **train.csv**: The training dataset containing features and the target variable `NObeyesdad`.\n- **test.csv**: The test dataset for which predictions need to be made.\n- **sample_submission.csv**: A template to demonstrate the required submission format.\n\n## 3. Problem Definition\nParticipants are tasked with predicting the obesity classification of individuals based on various demographic and lifestyle features. The target variable `NObeyesdad` categorizes individuals into different obesity risk levels.\n\n## 4. Data Information\n### 4.1 Data type\n#### 4.1.1 ID type\n- `id`: Unique identifier for each data point (not used in model training).\n\n#### 4.1.2 Numerical type\n- `Age`: Age of individuals (in years).\n- `Height`: Height of individuals (in meters).\n- `Weight`: Weight of individuals (in kilograms).\n- `CH2O`: Daily water intake (liters).\n- `FAF`: Frequency of physical activity.\n- `TUE`: Time spent exercising (in hours).\n- `CALC`: Daily calcium intake (grams).\n\n#### 4.1.3 Categorical type\n- `Gender`: Gender of individuals (Male/Female).\n- `family_history_with_overweight`: Family history of overweight (yes/no).\n- `FAVC`: Food intake frequency (yes/no).\n- `FCVC`: Frequency of vegetable consumption (numerical scale).\n- `NCP`: Number of meals consumed per day (numerical scale).\n- `CAEC`: Consumption of food between meals (categorical).\n- `SMOKE`: Smoking status (yes/no).\n- `SCC`: Self-calculated calories (yes/no).\n- `MTRANS`: Means of transportation (categorical).\n- `NObeyesdad`: Level of obesity (target variable).\n\n#### 4.1.4 Datetime type\n- None.\n\n### 4.2 Detailed data description\nThe dataset consists of training and test segments, capturing demographic and lifestyle information. The target variable `NObeyesdad` classifies individuals into obesity levels ranging from \"Insufficient Weight\" to \"Obesity Type III.\" The training data includes various age groups, height and weight variations, and lifestyle behaviors.\n\n## 5. Target Variable\nThe target variable `NObeyesdad` categorizes obesity levels into the following classes:\n- \"Insufficient Weight\"\n- \"Normal Weight\"\n- \"Overweight Level I\"\n- \"Overweight Level II\"\n- \"Obesity Type I\"\n- \"Obesity Type II\"\n- \"Obesity Type III\"\n\n## 6. Evaluation Metrics\nSubmissions will be evaluated based on the accuracy score, which measures the proportion of correctly predicted classifications.\n\n## 7. Submission Format\nThe submission file must include the following columns:\n- `id`: Unique identifier for each data point.\n- `NObeyesdad`: Predicted obesity classification.\n\nAn example submission format:\n```\nid,NObeyesdad\n20758,Normal_Weight\n20759,Normal_Weight\n20760,Obesity Type I\n```\n\n## 8. Other Key Aspects\n- The competition utilizes a synthetically generated dataset, allowing for a balance between real-world data characteristics and confidentiality of test labels.\n- Participants are encouraged to explore data visualizations, clustering, and exploratory data analysis (EDA) as part of their solutions.\n- Prizes consist of Kaggle merchandise, with limitations on multiple wins by the same individual.\n\n# TASK\n\nYou are now designing ML tools for the current development phase: Model Building, Validation, and Prediction.\nYour tools should include BOTH:\n1. Dataset-specific tools: Tailored to the unique characteristics of this dataset\n2. Commonly reusable tools: General-purpose utilities applicable across data science tasks\n\nThe Planner and Developer will use these tools to execute tasks in this phase.\nI will provide you with DATASET BACKGROUND, PHASE Information, and previous reports and plans.\n\nYou can use the following reasoning pattern to design the tools:\n1. Understand the dataset domain and phase objectives.\n2. Identify dataset-specific needs (e.g., domain-specific transformations, dataset-specific patterns)\n3. Identify commonly needed operations for this phase type (e.g., standard EDA plots, generic cleaners)\n4. For each tool, ask yourself and answer:\n    - \"Is this tool dataset-specific or generally reusable?\"\n    - \"What parameters should this tool accept to be flexible?\"\n    - \"Which data types (numerical, categorical, datetime, ID) does this tool handle?\"\n    - \"What are the expected inputs and outputs?\"\n    - \"What constraints or edge cases must the tool handle?\"\n5. Ensure tools are:\n    - Phase-appropriate (EDA tools differ from cleaning or feature engineering tools)\n    - Well-balanced (mix of specific + general utilities)\n    - Well-documented (clear parameter descriptions, applicable situations, and usage notes)\n    - Compliant with README format (Markdown documentation)\n\nDesign as many tools as needed to comprehensively support this phase, but prioritize quality over quantity.\nFocus on tools that will be most useful to the Planner and Developer.\n\nImportant: Strongly prioritize domain-specific (dataset background-aware) tools whenever they provide clear value. Make their domain rationale explicit so users understand why they are beneficial for this dataset.\n\n\n# CONSTRAINTS\n\n## CONSTRAINTS ##\n1. Tool Balance:\n   - Design tools appropriate for phase: Model Building, Validation, and Prediction\n   - Include BOTH dataset-specific AND generic data science tools\n   - Prioritize dataset-specific tools when they add measurable value (keep a healthy mix)\n   - Prioritize quality and usefulness over quantity\n   \n2. Technical Requirements:\n   - Use only: pandas, numpy, scikit-learn, scipy, matplotlib, seaborn\n   - No file I/O operations inside tools\n   - No network calls or external dependencies\n   - All tools must be pure functions (no global state modifications)\n\n3. Design Principles:\n   - Parameterize column names (never hard-code feature names)\n   - Provide clear, actionable error messages\n   - Handle edge cases gracefully (empty DataFrames, missing columns, wrong types)\n   - Include type hints for all parameters and return values\n   - Document assumptions and limitations in notes\n   - Mark in description whether tool is \"dataset-specific\" or \"generic\"\n   - For dataset-specific tools, include a brief \"Domain rationale\" note explaining why the tool fits this dataset background\n\n4. Output Requirements:\n   - Each tool MUST have markdown documentation\n   - Follow exact README format for Markdown\n\n\n#############\n# START TOOL DESIGN #\nBefore you begin, please request the following information from me, which contain important information that will guide your tool design for current phase:\n0. CURRENT phase specific tool GUIDELINES\n1. CURRENT phase available features\n2. CURRENT phase data preview\n3. Previous phases' plans and reports\n"
    },
    {
        "role": "assistant",
        "content": "Thank you! To proceed with designing the most effective and relevant tools for the Model Building, Validation, and Prediction phase, please provide the following information:\n\n0. **CURRENT phase specific tool GUIDELINES**  \n   (Any instructions or priorities for tool design in this phase)\n\n1. **CURRENT phase available features**  \n   (Which features are available for modeling? Have any been dropped, combined, or engineered?)\n\n2. **CURRENT phase data preview**  \n   (Representative rows or summary statistics of the train/test data in this phase)\n\n3. **Previous phases' plans and reports**  \n   (Key findings, recommendations, and decisions from earlier phases\u2014especially regarding data cleaning, feature engineering, and EDA)\n\nOnce you provide these, I will design a robust set of tools tailored for both dataset-specific and general ML needs for this competition phase."
    },
    {
        "role": "user",
        "content": "\n## TASK: PRODUCE A COMPLETE PYTHON MODULE OF TOOLS ##\n\nYou are designing tools for the current phase: Model Building, Validation, and Prediction.\n## PHASE-SPECIFIC TOOL GUIDELINES ##:\n\n- Focus on: training helpers, evaluation utilities, hyperparameter search wrappers, and model fit/predict functions that respect domain constraints (e.g., grouped/time-aware CV)\n- Example tools: cross-validation scorer with multiple metrics, model ensemble builder, prediction calibrator, and lightweight wrappers to fit/evaluate models\n- Additionally: provide multiple model wrappers with a UNIFORM interface so the Planner and Developer can use to compare performance across algorithms.\n   - Implement at least three `scikit-learn` model wrappers (e.g., LogisticRegression, RandomForestClassifier/Regressor, SVC/SVR, sklearn-compatible neural network).\n   - Each wrapper should be named `fit_and_evaluate_<algorithm>` and accept train/test data and configuration.\n   - Each wrapper must perform cross-validation when applicable and return a standardized metrics dict for comparison.\n   - Document an explicit \"Return schema\" in the docstring listing exact keys and types.\n\n\nUsing the Context provided below, generate a SINGLE Python module that contains multiple functions.\n\nStrict rules:\n- Follow the style of functions in `ml_tools.py` (clear docstrings: Args, Returns, Raises, Examples when helpful)\n- Use only pandas, numpy, scikit-learn, scipy.stats (standard library allowed); no file/network I/O\n- Pure functions: do not mutate global state; return results explicitly\n- Parameterize column names; no hard-coded feature names\n- Validate inputs and raise ValueError/TypeError with actionable messages\n- Type-hint all parameters and return values\n- Consolidate imports at the top; avoid duplicates\n - For the Model Building phase specifically: include at least three `scikit-learn` model wrappers with a common interface (`fit_and_evaluate_<algo>`), and document an explicit standardized Return schema (keys for metrics, `cv_scores`, `model_name`, `estimator`).\n\nOutput format:\n- Return EXACTLY one fenced Python block containing the entire module content\n- Start with imports, then define all functions\n- One function per tool, snake_case names\n- Define and use consistent, unambiguous key names in returned dicts and DataFrame columns; avoid synonyms. Include an explicit \"Return schema\" in the docstring listing exact keys and types.\n\n\nModule composition guidance:\n- Include BOTH dataset-specific and reusable tools for the phase\n- Focus on high-utility, phase-appropriate tools\n - Prefer LESS THAN 10 tools rather than many superficial ones\n- Prefer domain-specific (dataset background-aware) tools where they provide clear benefit; include a brief \"Domain rationale\" in each such function's docstring or notes\n\nContext:\nPhase: Model Building, Validation, and Prediction\nCompetition: obesity_risks\nCURRENT phase available features:\n\n#############\n# TARGET VARIABLE #\n['NObeyesdad']\n#############\n# PROCESSED TRAIN DATA WITH FEATURES #\nid,Age,Height,Weight,FCVC,NCP,CH2O,FAF,TUE,BMI,BMI_category,lifestyle_risk_score,age_lifestyle_interaction,bmi_weight_interaction,lifestyle_balance,Age_std,Height_std,Weight_std,FCVC_std,NCP_std,CH2O_std,FAF_std,TUE_std,BMI_std,lifestyle_risk_score_std,age_lifestyle_interaction_std,bmi_weight_interaction_std,lifestyle_balance_std,Gender_Female,Gender_Male,family_history_with_overweight_no,family_history_with_overweight_yes,FAVC_no,FAVC_yes,CAEC_Always,CAEC_Frequently,CAEC_No,CAEC_Sometimes,SMOKE_no,SMOKE_yes,SCC_no,SCC_yes,CALC_Frequently,CALC_No,CALC_Sometimes,MTRANS_Automobile,MTRANS_Bike,MTRANS_Motorbike,MTRANS_Public_transportation,MTRANS_Walking,BMI_category_Underweight,BMI_category_Normal_weight,BMI_category_Overweight,BMI_category_Obesity_I,BMI_category_Obesity_II,BMI_category_Obesity_III,n_flags,NObeyesdad\n\n#############\n# PROCESSED TEST DATA WITH FEATURES #\nid,Age,Height,Weight,FCVC,NCP,CH2O,FAF,TUE,BMI,BMI_category,lifestyle_risk_score,age_lifestyle_interaction,bmi_weight_interaction,lifestyle_balance,Age_std,Height_std,Weight_std,FCVC_std,NCP_std,CH2O_std,FAF_std,TUE_std,BMI_std,lifestyle_risk_score_std,age_lifestyle_interaction_std,bmi_weight_interaction_std,lifestyle_balance_std,Gender_Female,Gender_Male,family_history_with_overweight_no,family_history_with_overweight_yes,FAVC_no,FAVC_yes,CAEC_Always,CAEC_Frequently,CAEC_No,CAEC_Sometimes,SMOKE_no,SMOKE_yes,SCC_no,SCC_yes,CALC_Frequently,CALC_No,CALC_Sometimes,MTRANS_Automobile,MTRANS_Bike,MTRANS_Motorbike,MTRANS_Public_transportation,MTRANS_Walking,BMI_category_Underweight,BMI_category_Normal_weight,BMI_category_Overweight,BMI_category_Obesity_I,BMI_category_Obesity_II,BMI_category_Obesity_III,n_flags\n\n#############\n# SUBMISSION FORMAT #\nid,NObeyesdad\n\n#############\n# EVALUATION METRIC #\n# Evaluation Metric\nAccuracy score (the proportion of correctly predicted classifications)\nCURRENT phase data preview:\nData preview:\n# Data Information\n\n## Data Type\n\n### ID type\n- **id** : Serves as the unique identifier for each data point. This feature is not used in model training.\n\n### Numerical type\n- **Age** : Age of the individual (continuous).\n- **Height** : Height of the individual in meters (continuous).\n- **Weight** : Weight of the individual in kilograms (continuous).\n- **FCVC** : Frequency of consumption of vegetables (continuous or ordinal).\n- **NCP** : Number of main meals per day (continuous or ordinal).\n- **CH2O** : Daily water consumption (continuous or ordinal).\n- **FAF** : Physical activity frequency (continuous or ordinal).\n- **TUE** : Time using technology devices (continuous or ordinal).\n- **BMI** : Body Mass Index (continuous, derived from height and weight).\n- **lifestyle_risk_score** : Composite score reflecting lifestyle risk (continuous).\n- **age_lifestyle_interaction** : Interaction term between age and lifestyle factors (continuous).\n- **bmi_weight_interaction** : Interaction term between BMI and weight (continuous).\n- **lifestyle_balance** : Calculated balance of lifestyle factors (continuous).\n- **Age_std, Height_std, Weight_std, FCVC_std, NCP_std, CH2O_std, FAF_std, TUE_std, BMI_std, lifestyle_risk_score_std, age_lifestyle_interaction_std, bmi_weight_interaction_std, lifestyle_balance_std** : Standardized versions of the above features (continuous).\n- **n_flags** : Count of certain binary flags set to True (integer).\n\n### Categorical type\n- **BMI_category** : Categorical BMI classification (e.g., Underweight, Normal_weight, Overweight, Obesity_I, Obesity_II, Obesity_III).\n- **Gender_Female, Gender_Male** : One-hot encoded binary variables for gender.\n- **family_history_with_overweight_no, family_history_with_overweight_yes** : One-hot encoded binary variables indicating family history of overweight.\n- **FAVC_no, FAVC_yes** : One-hot encoded binary variables for frequent consumption of high caloric food.\n- **CAEC_Always, CAEC_Frequently, CAEC_No, CAEC_Sometimes** : One-hot encoded binary variables for frequency of consumption of food between meals.\n- **SMOKE_no, SMOKE_yes** : One-hot encoded binary variables for smoking status.\n- **SCC_no, SCC_yes** : One-hot encoded binary variables for monitoring calorie consumption.\n- **CALC_Frequently, CALC_No, CALC_Sometimes** : One-hot encoded binary variables for alcohol consumption.\n- **MTRANS_Automobile, MTRANS_Bike, MTRANS_Motorbike, MTRANS_Public_transportation, MTRANS_Walking** : One-hot encoded binary variables for main mode of transportation.\n- **BMI_category_Underweight, BMI_category_Normal_weight, BMI_category_Overweight, BMI_category_Obesity_I, BMI_category_Obesity_II, BMI_category_Obesity_III** : One-hot encoded binary variables for BMI category.\n- **NObeyesdad** : Target variable (multi-class categorical).\n\n### Datetime type\n- None present in the data.\n\n## Detailed data description\n\nThe dataset is designed for multi-class classification of obesity status based on a wide variety of anthropometric, lifestyle, and demographic features. Each row represents an individual, identified uniquely by the `id` field. The features are a mix of:\n- Directly observed (e.g., Age, Height, Weight)\n- Derived (e.g., BMI, BMI_category)\n- Engineered (e.g., lifestyle_risk_score, interaction terms, and their standardized forms)\n- One-hot encoded categorical variables representing various lifestyle, demographic, and behavioral attributes.\n\nKey characteristics and notable patterns:\n- The dataset is highly engineered, with many features representing interactions and standardized values, likely to improve model performance or address feature scaling.\n- Categorical features have been extensively one-hot encoded.\n- The `BMI` and `BMI_category` features reflect typical medical BMI cutoffs.\n- The target variable, `NObeyesdad`, represents specific classes of weight status (e.g., \"Obesity_Type_II\", \"Normal_Weight\", \"Insufficient_Weight\"), suggesting an emphasis on nuanced prediction of obesity levels.\n- No obvious missing values or datetime types.\n- Submission and test files appear to follow the same feature schema, except for the target variable, which is only in the train set.\n\n## Target Variable\n\n- **NObeyesdad**: The target variable represents the obesity status of the individual. It is a multi-class categorical variable with labels such as:\n  - Insufficient_Weight\n  - Normal_Weight\n  - Overweight_Level_I\n  - Overweight_Level_II\n  - Obesity_Type_I\n  - Obesity_Type_II\n  - Obesity_Type_III\n\n## Submission format (if applicable)\n\nThe submission file should have the following columns:\n- **id** (integer): Unique identifier corresponding to each test data point.\n- **NObeyesdad** (string): Predicted obesity status for the individual.\n\n**Example:**\n| id    | NObeyesdad       |\n|-------|------------------|\n| 20758 | Normal_Weight    |\n| 20759 | Normal_Weight    |\n| ...   | ...              |\n\nAll rows from the test set must be included, with `NObeyesdad` containing one of the valid class labels.\nPrevious Plans and Reports:\n## UNDERSTAND BACKGROUND ##\nThere is no plan in this phase.\n## PRELIMINARY EXPLORATORY DATA ANALYSIS ##\nPreliminary Exploratory Data Analysis Plan\n## PLAN\n\n### STEP 1\nTask: Summarize and audit feature types, basic statistics, unique values, and missingness for all features in both train and test datasets.\nTools, involved features and correct parameters:\n- Tools:\n  - `summarize_numerical_features` for numerical features (`Age`, `Height`, `Weight`, `FCVC`, `NCP`, `CH2O`, `FAF`, `TUE`)\n  - `summarize_categorical_features` for categorical features (`Gender`, `family_history_with_overweight`, `FAVC`, `CAEC`, `SMOKE`, `SCC`, `CALC`, `MTRANS`, and `NObeyesdad` for train)\n  - Pandas `.is_unique` and `.isnull().sum()` for `id`\n- Parameters:\n  - Use both train and test dataframes\nExpected output or Impact on data:\n- Text tables summarizing statistics, unique values, and missing counts for each feature group\n- Text summary on `id` column uniqueness and missingness\n- No changes to data; purely descriptive\nConstraints:\n- No data modification\n- Use only text/print outputs for summaries\n\n### STEP 2\nTask: Analyze initial distributions for all features to identify basic patterns and spot potential data entry errors or outliers.\nTools, involved features and correct parameters:\n- Tools:\n  - `plot_numerical_distributions` for numerical features (`Age`, `Height`, `Weight`, `FCVC`, `NCP`, `CH2O`, `FAF`, `TUE`)\n    - Parameters: No target hue, `n_cols=3`, `figsize=(16, 8)`\n  - `plot_categorical_counts` for categorical features (`Gender`, `family_history_with_overweight`, `FAVC`, `CAEC`, `SMOKE`, `SCC`, `CALC`, `MTRANS`)\n    - Parameters: `n_cols=3`, `figsize=(16, 8)`\n- Use train data primarily; test data if feasible\nExpected output or Impact on data:\n- Histograms for numerical features and countplots for categorical features (max 10 images in total)\n- Descriptions before each plot\n- No changes to data; visual inspection only\nConstraints:\n- Limit to 10 total images\n- Focus on critical, representative plots\n\n### STEP 3\nTask: Detect and quantify outliers and check consistency of numerical features (including BMI).\nTools, involved features and correct parameters:\n- Tools:\n  - `automated_outlier_detector` for numerical features (`Age`, `Height`, `Weight`, `FCVC`, `NCP`, `CH2O`, `FAF`, `TUE`)\n    - Parameters: `method='iqr'`, `threshold=1.5`\n  - `bmi_feature_analysis` for BMI calculation using `Height` and `Weight`\n    - Parameters: `height_col='Height'`, `weight_col='Weight'`\n- Apply to train and test data\nExpected output or Impact on data:\n- Text tables with outlier counts and ratios for each numerical feature\n- BMI summary statistics (mean, std, min, max, quartiles)\n- Text report flagging implausible BMI values\n- No changes to data; purely diagnostic\nConstraints:\n- No correction or removal of data\n- All outputs in text except for BMI summary if plot is critical (counted in image quota)\n\n### STEP 4\nTask: Assess target variable distribution and its relationship with key features in train data.\nTools, involved features and correct parameters:\n- Tools:\n  - `analyze_target_distribution` for `NObeyesdad`\n  - `feature_vs_target_boxplot` for `Age`, `Weight`, `Height`, and BMI vs. `NObeyesdad`\n    - Parameters: one plot per feature, `figsize=(8, 5)`\n  - Pandas crosstab for `Gender` vs. `NObeyesdad`\n- Use train data only\nExpected output or Impact on data:\n- Text table of target class counts and proportions\n- Up to 4 boxplots (key numerical features vs. target, within image quota)\n- Crosstab of `Gender` vs. target (text)\n- Descriptions before each output\n- No data changes; foundational understanding of target and its relationships\nConstraints:\n- Do not exceed 10 total images (across all steps)\n- Prioritize boxplots for BMI and Weight if image quota is tight\n- No deep association or multivariate analysis at this stage\n## DATA CLEANING ##\nData Cleaning Plan\n## PLAN\n\n### STEP 1\nTask: Enforce correct data types and clean invalid values for all features.\nTools, involved features and correct parameters:\n- **numerical_type_enforcer**: For numerical features (`Age`, `Height`, `Weight`, `FCVC`, `NCP`, `CH2O`, `FAF`, `TUE`), coerce to float, fill invalids with median (computed on train, applied to both train/test).\n- **gender_cleaner**: For `Gender`, valid values `(\"Male\", \"Female\")`, fill invalid/missing with mode from train.\n- **categorical_binary_cleaner**: For binary categorical features (`family_history_with_overweight`, `FAVC`, `SMOKE`, `SCC`), valid values `(\"yes\", \"no\")`, fill invalid/missing with mode.\n- **ordinal_categorical_cleaner**: For ordinal categorical features (`CAEC`, `CALC`), valid order `[\"no\", \"Sometimes\", \"Frequently\", \"Always\"]`, fill invalid/missing with mode or `\"no\"` if ambiguous.\n- **Manual harmonization**: For `MTRANS`, normalize string values and harmonize categories between train and test.\nExpected output or Impact on data: All features have correct types, no invalid values, and categories are consistent across train and test.\nConstraints: Do not drop or encode features at this stage; changes must be applied identically to train and test (except `NObeyesdad`, which is train-only).\n\n### STEP 2\nTask: Handle and impute missing values for all features.\nTools, involved features and correct parameters:\n- For numerical features, after type enforcement, use **impute_missing_by_group_median**:\n  - For `Height`, `Weight`, `Age`: group by `Gender` for imputation.\n  - For `FCVC`, `NCP`, `CH2O`, `FAF`, `TUE`: use overall median.\n- For categorical features, fill missing with mode or specified fill value in related cleaning tools.\nExpected output or Impact on data: No missing values in any feature in either train or test set.\nConstraints: Imputation statistics must be based on train data and applied identically to test; do not use target or future data for imputation.\n\n### STEP 3\nTask: Detect and treat outliers and implausible values in numerical features, especially BMI-related.\nTools, involved features and correct parameters:\n- **bmi_validator_and_flagger**: Calculate BMI from `Height` and `Weight`, flag implausible BMI (`BMI < 10` or `BMI > 80`), add `BMI` and `BMI_flag` columns.\n- For rows with `BMI_flag==True`:\n  - If BMI is just outside thresholds and height/weight plausible, use **cap_outliers** at 1st/99th percentiles.\n  - If BMI is far outside plausible range, drop record (train only) or cap/impute in test.\n- **iqr_outlier_flagger**: For each numerical feature, flag outliers (`iqr_mult=1.5`).\n- **cap_outliers**: Winsorize flagged numerical outliers at 1st/99th percentiles.\nExpected output or Impact on data: No implausible BMI or extreme outliers; distributions are robust and realistic.\nConstraints: Do not drop any rows from test; only cap or impute. Train set may drop records only if BMI is far outside plausible human range.\n\n### STEP 4\nTask: Harmonize categorical feature levels and handle rare categories.\nTools, involved features and correct parameters:\n- **handle_rare_categories**: For categorical features with >5 unique categories or rare entries (especially `MTRANS`, `CAEC`, `CALC`), set `threshold=10`, replace rare classes with `\"Rare\"`.\n- Check that all test categories exist in train; if not, map to `\"Rare\"`.\n- Harmonize spelling/capitalization of all categorical features between train and test.\nExpected output or Impact on data: All categorical features have consistent, clean, and manageable value sets across train and test.\nConstraints: Do not drop rows for rare categories; only relabel. No feature encoding or transformation at this phase.\n## IN-DEPTH EXPLORATORY DATA ANALYSIS ##\nIn-depth Exploratory Data Analysis Plan\n## PLAN\n\n### STEP 1\nTask: Advanced Univariate and Bivariate Analysis by Feature Type  \nTools, involved features and correct parameters:  \n- **Numerical Features** (`Age`, `Height`, `Weight`, `FCVC`, `NCP`, `CH2O`, `FAF`, `TUE`, `BMI`):\n  - `target_stratified_numerical_summary` (for group-wise stats by obesity class)\n  - `target_vs_feature_anova` (test for significant differences across classes)\n- **Categorical Features** (`Gender`, `family_history_with_overweight`, `FAVC`, `CAEC`, `SMOKE`, `SCC`, `CALC`, `MTRANS`):\n  - `summarize_categorical_features` (overview)\n  - `categorical_vs_target_chi2` (association test with target)\nExpected output or Impact on data:  \n- Text-based summary tables showing statistics for each feature stratified by target\n- Textual results of ANOVA and Chi-squared tests, highlighting significant feature-target associations\n- No changes to data\nConstraints:  \n- No data modification\n- Output is text unless patterns are not clear from text alone\n\n### STEP 2\nTask: Obesity Class Segmentation & Lifestyle Subgroup Analysis  \nTools, involved features and correct parameters:  \n- `segment_bmi_by_obesity_class` (BMI stats segmented by obesity class, excluding outliers via `BMI_flag`)\n- `lifestyle_segment_obesity_rate` (obesity prevalence tables for each of: `FAVC`, `SMOKE`, `SCC`, `MTRANS`, `CAEC`)\nExpected output or Impact on data:  \n- Text tables summarizing BMI by obesity class and obesity rates within lifestyle subgroups\n- Highlights of class overlap, labeling issues, and high-risk subgroups\nConstraints:  \n- Results as text tables; only generate a visualization if subgroup differences are dramatic and not clear in text\n\n### STEP 3\nTask: Feature Interaction and Multicollinearity Assessment  \nTools, involved features and correct parameters:  \n- `feature_interaction_heatmap` (all numerical features including `BMI`, excluding outlier flags, method=`pearson`, `figsize=(10, 8)`)\nExpected output or Impact on data:  \n- One heatmap visualizing numerical feature correlations\n- Text interpretation of strongest correlations and implications for redundancy or feature engineering\nConstraints:  \n- Limit to one image (the heatmap); all other outputs in text\n\n### STEP 4\nTask: Key Visualization of Feature-Target Patterns  \nTools, involved features and correct parameters:  \n- For up to three numerical features with strongest ANOVA results, use `feature_vs_target_boxplot` (`figsize=(8, 5)`)\n- If a categorical feature shows a strong chi2 association, optionally use a countplot colored by target\nExpected output or Impact on data:  \n- Up to three boxplots (numerical feature vs. target) and one countplot (categorical feature by target), each with descriptive text\n- Visual confirmation and illustration of non-obvious or strongly discriminative patterns\nConstraints:  \n- Maximum of four images including heatmap from Step 3\n- Each plot must be justified by prior statistical findings\n- All plots accompanied by text descriptions and interpretations\n## FEATURE ENGINEERING ##\nFeature Engineering Plan\n## PLAN\n\n### STEP 1\nTask: Create and transform domain-specific composite features based on EDA findings and medical guidelines.\nTools, involved features and correct parameters:\n- `create_bmi_category_feature`: Create `BMI_category` from `BMI` using standard WHO thresholds.\n- `create_lifestyle_risk_score`: Generate `lifestyle_risk_score` using `FAVC`, `CAEC`, `CALC`, `SCC`, `SMOKE`, `FCVC`, `CH2O`, `FAF`, `TUE`.\n- `create_age_lifestyle_interaction`: Generate `age_lifestyle_interaction` from `Age`, `FAVC`, `FCVC`, `FAF`.\n- `create_bmi_weight_interaction`: Generate `bmi_weight_interaction` from `BMI`, `Weight`.\n- `create_lifestyle_balance_feature`: Generate `lifestyle_balance` from `FAF`, `TUE`.\nExpected output or Impact on data:\n- Adds new columns: `BMI_category`, `lifestyle_risk_score`, `age_lifestyle_interaction`, `bmi_weight_interaction`, `lifestyle_balance` to both train and test sets.\nConstraints:\n- Apply identically to both train and test. Do not use the target variable in feature creation. Use default tool parameters unless otherwise specified.\n\n### STEP 2\nTask: Encode and transform categorical features for model readiness.\nTools, involved features and correct parameters:\n- `one_hot_encode_columns`: Apply to all categorical features except `id` and the target (`Gender`, `family_history_with_overweight`, `FAVC`, `CAEC`, `SMOKE`, `SCC`, `CALC`, `MTRANS`, and engineered `BMI_category`), with `drop_original=False`.\n- Optionally, `target_mean_encoding`: For high-cardinality variables (e.g., `MTRANS`), fit on train and apply mapping to test, using ordinal encoding of `NObeyesdad` as required.\nExpected output or Impact on data:\n- Produces one-hot encoded columns for each category. Categorical features become usable for modeling.\nConstraints:\n- Ensure all categories in test are present in train, map unseen to \"Rare\" if needed. Do not remove original categorical columns unless explicitly required.\n\n### STEP 3\nTask: Standardize numerical and composite features, and aggregate outlier/flag columns.\nTools, involved features and correct parameters:\n- `standardize_numerical_features`: Standardize raw (`Age`, `Height`, `Weight`, `FCVC`, `NCP`, `CH2O`, `FAF`, `TUE`, `BMI`) and engineered features (`lifestyle_risk_score`, `age_lifestyle_interaction`, `bmi_weight_interaction`, `lifestyle_balance`), with suffix `\"_std\"`.\n- `aggregate_flag_features`: Aggregate all boolean flag columns (ending with `_flag`) into a single count column `n_flags`.\nExpected output or Impact on data:\n- Standardized versions (z-score) of all selected features; new column `n_flags` summarizing anomaly flags.\nConstraints:\n- Compute standardization parameters on train, apply to test. Do not overwrite original features\u2014retain both raw and standardized versions.\n\n### STEP 4\nTask: Perform feature selection and prepare final output files.\nTools, involved features and correct parameters:\n- Manual selection: Exclude `id`, duplicate/redundant features, and all individual flag columns (retain only `n_flags`), and any columns used only for intermediate calculation.\n- Export: Save final features and `NObeyesdad` (train only) to `processed_train.csv` and `processed_test.csv`.\nExpected output or Impact on data:\n- Two files: `processed_train.csv` and `processed_test.csv`, containing only relevant and engineered features, ready for modeling.\nConstraints:\n- Do not remove features unless justified. Provide a clear list of included features for reproducibility.\n\nFeature Engineering Report\n# FEATURE INFO\n## TARGET VARIABLE\nNObeyesdad\n## FEATURES BEFORE THIS PHASE\n['id', 'Gender', 'Age', 'Height', 'Weight', 'family_history_with_overweight', 'FAVC', 'FCVC', 'NCP', 'CAEC', 'SMOKE', 'CH2O', 'SCC', 'FAF', 'TUE', 'CALC', 'MTRANS', 'NObeyesdad', 'BMI', 'BMI_flag', 'Age_outlier_flag', 'Height_outlier_flag', 'Weight_outlier_flag', 'FCVC_outlier_flag', 'NCP_outlier_flag', 'CH2O_outlier_flag', 'FAF_outlier_flag', 'TUE_outlier_flag', 'BMI_outlier_flag']\n## FEATURES AFTER THIS PHASE\n['id', 'Age', 'Height', 'Weight', 'FCVC', 'NCP', 'CH2O', 'FAF', 'TUE', 'BMI', 'BMI_category', 'lifestyle_risk_score', 'age_lifestyle_interaction', 'bmi_weight_interaction', 'lifestyle_balance', 'Age_std', 'Height_std', 'Weight_std', 'FCVC_std', 'NCP_std', 'CH2O_std', 'FAF_std', 'TUE_std', 'BMI_std', 'lifestyle_risk_score_std', 'age_lifestyle_interaction_std', 'bmi_weight_interaction_std', 'lifestyle_balance_std', 'Gender_Female', 'Gender_Male', 'family_history_with_overweight_no', 'family_history_with_overweight_yes', 'FAVC_no', 'FAVC_yes', 'CAEC_Always', 'CAEC_Frequently', 'CAEC_No', 'CAEC_Sometimes', 'SMOKE_no', 'SMOKE_yes', 'SCC_no', 'SCC_yes', 'CALC_Frequently', 'CALC_No', 'CALC_Sometimes', 'MTRANS_Automobile', 'MTRANS_Bike', 'MTRANS_Motorbike', 'MTRANS_Public_transportation', 'MTRANS_Walking', 'BMI_category_Underweight', 'BMI_category_Normal_weight', 'BMI_category_Overweight', 'BMI_category_Obesity_I', 'BMI_category_Obesity_II', 'BMI_category_Obesity_III', 'n_flags', 'NObeyesdad']\n# REPORT\n\n## QUESTIONS AND ANSWERS  \n\n### Question 1\nWhat files did you process? Which files were generated? Answer with detailed file path.\n### Answer 1\nThe following files were processed during the feature engineering phase:\n- **Processed Input Files**:\n  - `cleaned_train.csv` located at `/Users/scottiejj/Desktop/AutoKaggle_APAPTED/multi_agents/competition/obesity_risks/`\n  - `cleaned_test.csv` located at `/Users/scottiejj/Desktop/AutoKaggle_APAPTED/multi_agents/competition/obesity_risks/`\n\n- **Generated Output Files**:\n  - `processed_train.csv` saved at `/Users/scottiejj/Desktop/AutoKaggle_APAPTED/multi_agents/competition/obesity_risks/`\n  - `processed_test.csv` saved at `/Users/scottiejj/Desktop/AutoKaggle_APAPTED/multi_agents/competition/obesity_risks/`\n\n### Question 2\nWhich features were involved in this phase? What changes did they undergo? If any feature types were modified, answer which features are modified and how they are modified. If any features were deleted or created, answer which features are deleted or created and provide detailed explanations. \n### Answer 2\nIn this phase, the following changes were made to the features:\n\n- **Created Features**:\n  - **BMI_category**: Categorical feature based on BMI thresholds from WHO guidelines.\n  - **lifestyle_risk_score**: Composite score combining multiple lifestyle factors.\n  - **age_lifestyle_interaction**: Interaction term between Age and lifestyle factors.\n  - **bmi_weight_interaction**: Interaction term between BMI and Weight.\n  - **lifestyle_balance**: Score representing balance between physical activity and technology use.\n\n- **Modified Features**:\n  - Categorical features such as `Gender`, `family_history_with_overweight`, `FAVC`, `CAEC`, `SMOKE`, `SCC`, `CALC`, `MTRANS`, and `BMI_category` underwent one-hot encoding, converting them into binary columns.\n\n- **Numerical Features**:\n  - Numerical features including `Age`, `Height`, `Weight`, `FCVC`, `NCP`, `CH2O`, `FAF`, `TUE`, and others were standardized using z-score normalization.\n\n- **Deleted Features**:\n  - Individual flag columns (e.g., `_flag` features) were excluded from the final dataset, retaining only the aggregated `n_flags` column.\n\n### Question 3\nWhat statistical transformations were applied to the numerical features, and how might these affect model performance?\n### Answer 3\nNumerical features were standardized using z-score normalization, which transforms the data to have a mean of 0 and a standard deviation of 1. This transformation was applied to the following features:\n- Age\n- Height\n- Weight\n- FCVC\n- NCP\n- CH2O\n- FAF\n- TUE\n- BMI\n- lifestyle_risk_score\n- age_lifestyle_interaction\n- bmi_weight_interaction\n- lifestyle_balance\n\nStandardization can improve model performance by ensuring that features are on the same scale, enhancing the convergence speed of optimization algorithms and reducing bias in models sensitive to feature scaling.\n\n### Question 4\nWhat feature selection criteria were used to determine which features to retain, and how many features are included in the final datasets?\n### Answer 4\nFeature selection was performed manually based on the following criteria:\n- Exclusion of the `id` column as it does not contribute to model prediction.\n- Removal of duplicate or redundant features.\n- Exclusion of individual flag columns, retaining only the aggregated `n_flags` column.\n\nThe final datasets included 58 features in the processed training set and 57 features in the processed test set.\n\n### Question 5\nWere there any interactions or composite features created that could significantly influence the model's predictive power? If so, which features are they?\n### Answer 5\nYes, several interaction and composite features were created that could significantly influence the model's predictive power:\n- **age_lifestyle_interaction**: Captures how age interacts with lifestyle factors, revealing age-related trends in obesity risk.\n- **bmi_weight_interaction**: Reflects the interaction between BMI and Weight, crucial for assessing obesity risk.\n- **lifestyle_risk_score**: Aggregates multiple lifestyle factors into a single metric, simplifying the interpretation of overall lifestyle risk.\n\nThese features are expected to provide additional predictive power by capturing non-linear relationships and interactions that are pivotal in health-related models.\n\n### Question 6\nWhat potential challenges or considerations should be kept in mind when transitioning to the Model Building phase, based on the feature engineering outcomes?\n### Answer 6\nWhen transitioning to the Model Building phase, consider the following challenges:\n- **Overfitting**: The introduction of numerous interaction and composite features may lead to overfitting, especially with models sensitive to feature complexity.\n- **Feature Importance**: Evaluating the importance of newly created features is essential, as some may not contribute significantly to model performance and could be candidates for exclusion.\n- **Multicollinearity**: The creation of interaction terms may introduce multicollinearity, affecting the stability and interpretability of certain models.\n- **Normalization Impact**: Ensure that all models used can effectively leverage standardized features, as some algorithms may require adaptations.\n\nThese considerations will help refine the modeling strategy to ensure robust and generalizable predictions.\n\n\n\n"
    },
    {
        "role": "assistant",
        "content": "```python\n\"\"\"\nobesity_risks_ml_tools.py\n\nA collection of phase-appropriate tools for Model Building, Validation, and Prediction\nin the 'obesity_risks' competition. Includes both dataset-specific and generic tools.\n\nAll tools are pure functions, parameterize all column names, validate inputs,\nand return results explicitly. Use only pandas, numpy, scikit-learn, and scipy.\n\nAuthor: Toolsmith Agent for obesity_risks\n\"\"\"\n\nimport numpy as np\nimport pandas as pd\nfrom typing import List, Dict, Any, Optional, Tuple, Union\nfrom sklearn.model_selection import StratifiedKFold, cross_val_score, cross_val_predict\nfrom sklearn.metrics import (\n    accuracy_score,\n    classification_report,\n    confusion_matrix,\n    f1_score,\n    log_loss,\n)\nfrom sklearn.linear_model import LogisticRegression\nfrom sklearn.ensemble import RandomForestClassifier\nfrom sklearn.svm import SVC\nfrom scipy.stats import mode\n\n\n############################\n# GENERIC MODELING TOOLS   #\n############################\n\ndef cross_validate_with_multiple_metrics(\n    X: pd.DataFrame,\n    y: pd.Series,\n    estimator,\n    cv: int = 5,\n    scoring: Optional[Dict[str, Any]] = None,\n    random_state: Optional[int] = None,\n) -> Dict[str, Any]:\n    \"\"\"\n    Performs cross-validation using multiple metrics and returns the mean and std for each.\n\n    Args:\n        X (pd.DataFrame): Feature matrix.\n        y (pd.Series): Target vector.\n        estimator: scikit-learn estimator.\n        cv (int): Number of folds for cross-validation.\n        scoring (dict, optional): Dict of scoring metrics (e.g., {'accuracy': ..., 'f1_macro': ...}).\n        random_state (int, optional): Random seed.\n\n    Returns:\n        Dict[str, Any]: Dictionary with scores for each metric.\n\n    Raises:\n        ValueError: If X or y are empty or have mismatching shapes.\n\n    Return schema:\n        {\n            'cv_scores': Dict[str, List[float]],\n            'mean_scores': Dict[str, float],\n            'std_scores': Dict[str, float],\n            'n_splits': int,\n            'estimator': estimator object,\n        }\n\n    Example:\n        scores = cross_validate_with_multiple_metrics(X, y, estimator, cv=5, scoring={'accuracy': 'accuracy', 'f1_macro': 'f1_macro'})\n    \"\"\"\n    if X.shape[0] == 0 or y.shape[0] == 0:\n        raise ValueError(\"X and y must not be empty.\")\n    if X.shape[0] != y.shape[0]:\n        raise ValueError(\"X and y must have the same number of rows.\")\n    if scoring is None:\n        scoring = {'accuracy': 'accuracy', 'f1_macro': 'f1_macro'}\n    cv_scores = {}\n    mean_scores = {}\n    std_scores = {}\n    for metric_name, metric in scoring.items():\n        scores = cross_val_score(\n            estimator,\n            X,\n            y,\n            cv=cv,\n            scoring=metric,\n            n_jobs=None,\n        )\n        cv_scores[metric_name] = scores.tolist()\n        mean_scores[metric_name] = np.mean(scores)\n        std_scores[metric_name] = np.std(scores)\n    return {\n        \"cv_scores\": cv_scores,\n        \"mean_scores\": mean_scores,\n        \"std_scores\": std_scores,\n        \"n_splits\": cv,\n        \"estimator\": estimator,\n    }\n\n\ndef get_classification_metrics(\n    y_true: Union[np.ndarray, pd.Series],\n    y_pred: Union[np.ndarray, pd.Series],\n    labels: Optional[List[str]] = None,\n    average: str = \"macro\"\n) -> Dict[str, Any]:\n    \"\"\"\n    Computes core classification metrics for predictions.\n\n    Args:\n        y_true (array-like): Ground truth target values.\n        y_pred (array-like): Predicted target values.\n        labels (list, optional): List of label names (for consistent order).\n        average (str): Averaging method for multi-class metrics.\n\n    Returns:\n        Dict[str, Any]: Dictionary with accuracy, f1, confusion matrix, and classification report.\n\n    Raises:\n        ValueError: If input lengths mismatch.\n\n    Return schema:\n        {\n            'accuracy': float,\n            'f1_macro': float,\n            'confusion_matrix': np.ndarray,\n            'classification_report': str,\n        }\n\n    Example:\n        metrics = get_classification_metrics(y_true, y_pred)\n    \"\"\"\n    if len(y_true) != len(y_pred):\n        raise ValueError(\"y_true and y_pred must have same length.\")\n    acc = accuracy_score(y_true, y_pred)\n    f1 = f1_score(y_true, y_pred, average=average, labels=labels)\n    conf_mat = confusion_matrix(y_true, y_pred, labels=labels)\n    class_report = classification_report(y_true, y_pred, labels=labels)\n    return {\n        \"accuracy\": acc,\n        \"f1_macro\": f1,\n        \"confusion_matrix\": conf_mat,\n        \"classification_report\": class_report,\n    }\n\n\n##############################################\n# DATASET-SPECIFIC DOMAIN-AWARE MODEL TOOLS  #\n##############################################\n\ndef obesity_grouped_stratified_kfold(\n    X: pd.DataFrame,\n    y: pd.Series,\n    group_col: Optional[str] = None,\n    n_splits: int = 5,\n    shuffle: bool = True,\n    random_state: Optional[int] = None,\n) -> StratifiedKFold:\n    \"\"\"\n    Returns a StratifiedKFold object. If group_col is provided, warns user and ignores it,\n    since group-wise splitting is not supported in this dataset (no group/id dependency).\n\n    Domain rationale:\n        Obesity risk is known to be stratified by categories such as BMI_category.\n        This function ensures stratified folds for balanced class distribution.\n\n    Args:\n        X (pd.DataFrame): Feature matrix.\n        y (pd.Series): Target labels.\n        group_col (str, optional): Column for group-aware CV (ignored here).\n        n_splits (int): Number of CV folds.\n        shuffle (bool): Whether to shuffle before splitting.\n        random_state (int, optional): Seed.\n\n    Returns:\n        StratifiedKFold: StratifiedKFold splitter.\n\n    Raises:\n        ValueError: If y is empty or n_splits < 2.\n\n    Return schema:\n        StratifiedKFold object (sklearn)\n\n    Example:\n        skf = obesity_grouped_stratified_kfold(X, y, n_splits=5)\n        for train_idx, val_idx in skf.split(X, y):\n            ...\n    \"\"\"\n    if y.empty:\n        raise ValueError(\"y must not be empty.\")\n    if n_splits < 2:\n        raise ValueError(\"n_splits must be >= 2.\")\n    if group_col is not None:\n        import warnings\n        warnings.warn(\"group_col supplied but ignored; no group-dependent splits in this dataset.\")\n    return StratifiedKFold(n_splits=n_splits, shuffle=shuffle, random_state=random_state)\n\n\ndef obesity_prediction_calibrator(\n    y_probs: np.ndarray,\n    class_labels: List[str],\n    method: str = \"argmax\"\n) -> np.ndarray:\n    \"\"\"\n    Calibrates predicted probabilities into final class labels.\n    Designed for multi-class obesity classification.\n\n    Domain rationale:\n        Ensures that calibrated predictions obey the class label schema and\n        properly handles ties or uncertain cases in obesity risk prediction.\n\n    Args:\n        y_probs (np.ndarray): Array of predicted probabilities (n_samples, n_classes).\n        class_labels (List[str]): List of class labels in order of columns in y_probs.\n        method (str): 'argmax' (default) or 'top2_random' (breaks ties randomly among top 2).\n\n    Returns:\n        np.ndarray: Predicted class labels (shape: n_samples,).\n\n    Raises:\n        ValueError: If y_probs shape does not match class_labels.\n\n    Return schema:\n        np.ndarray of shape (n_samples,) with class label strings.\n\n    Example:\n        preds = obesity_prediction_calibrator(y_probs, class_labels)\n    \"\"\"\n    if y_probs.shape[1] != len(class_labels):\n        raise ValueError(\"y_probs columns must match length of class_labels.\")\n    if method not in {\"argmax\", \"top2_random\"}:\n        raise ValueError(\"method must be 'argmax' or 'top2_random'.\")\n    if method == \"argmax\":\n        preds = np.array([class_labels[i] for i in np.argmax(y_probs, axis=1)])\n    else:  # \"top2_random\"\n        preds = []\n        for row in y_probs:\n            top_val = np.max(row)\n            top_idxs = np.where(row == top_val)[0]\n            if len(top_idxs) == 1:\n                preds.append(class_labels[top_idxs[0]])\n            else:\n                chosen = np.random.choice(top_idxs)\n                preds.append(class_labels[chosen])\n        preds = np.array(preds)\n    return preds\n\n\ndef obesity_submission_formatter(\n    ids: pd.Series,\n    preds: Union[np.ndarray, List[str]],\n    id_col: str = \"id\",\n    target_col: str = \"NObeyesdad\"\n) -> pd.DataFrame:\n    \"\"\"\n    Formats predictions for the obesity_risks competition submission.\n\n    Domain rationale:\n        Ensures outputs match required Kaggle schema with id and target columns.\n        Handles ordering and formatting reliably for this specific competition.\n\n    Args:\n        ids (pd.Series): Series of IDs from the test set.\n        preds (np.ndarray or list): Predicted class labels.\n        id_col (str): Name for the ID column.\n        target_col (str): Name for the prediction column.\n\n    Returns:\n        pd.DataFrame: Submission-ready DataFrame.\n\n    Raises:\n        ValueError: If lengths do not match.\n\n    Return schema:\n        DataFrame with columns [id_col, target_col], shape (n_samples, 2)\n\n    Example:\n        sub_df = obesity_submission_formatter(test_df['id'], preds)\n    \"\"\"\n    if len(ids) != len(preds):\n        raise ValueError(\"ids and preds must have the same length.\")\n    df = pd.DataFrame({id_col: ids, target_col: preds})\n    return df\n\n\n##############################################################\n# UNIFORM INTERFACE: MODEL WRAPPERS FOR ALGORITHM COMPARISON #\n##############################################################\n\ndef fit_and_evaluate_logistic_regression(\n    X: pd.DataFrame,\n    y: pd.Series,\n    X_val: Optional[pd.DataFrame] = None,\n    y_val: Optional[pd.Series] = None,\n    *,\n    feature_cols: Optional[List[str]] = None,\n    target_labels: Optional[List[str]] = None,\n    cv: int = 5,\n    random_state: Optional[int] = None,\n    solver: str = \"liblinear\",\n    max_iter: int = 500,\n    return_estimator: bool = True,\n) -> Dict[str, Any]:\n    \"\"\"\n    Trains and evaluates a Logistic Regression classifier with cross-validation.\n\n    Args:\n        X (pd.DataFrame): Training features.\n        y (pd.Series): Training labels.\n        X_val (pd.DataFrame, optional): Validation features for out-of-sample evaluation.\n        y_val (pd.Series, optional): Validation labels.\n        feature_cols (List[str], optional): Subset of features to use. If None, use all.\n        target_labels (List[str], optional): List of all class labels (for metrics/report).\n        cv (int): Cross-validation folds.\n        random_state (int, optional): Seed.\n        solver (str): Solver for LogisticRegression.\n        max_iter (int): Max iterations for LogisticRegression.\n        return_estimator (bool): If True, return fitted estimator.\n\n    Returns:\n        Dict[str, Any]: Results including fitted model, CV metrics, and val metrics.\n\n    Raises:\n        ValueError: If data is invalid or shapes mismatch.\n\n    Return schema:\n        {\n            'model_name': str,\n            'estimator': LogisticRegression,\n            'cv_scores': Dict[str, List[float]],\n            'mean_scores': Dict[str, float],\n            'std_scores': Dict[str, float],\n            'val_metrics': Dict[str, Any] or None,\n            'n_features': int,\n            'n_samples': int,\n        }\n\n    Example:\n        results = fit_and_evaluate_logistic_regression(X, y, X_val, y_val, feature_cols=col_list)\n    \"\"\"\n    if feature_cols is not None:\n        X_use = X[feature_cols]\n        Xv_use = X_val[feature_cols] if X_val is not None else None\n    else:\n        X_use = X.copy()\n        Xv_use = X_val.copy() if X_val is not None else None\n\n    lr = LogisticRegression(\n        multi_class=\"auto\",\n        solver=solver,\n        max_iter=max_iter,\n        random_state=random_state,\n    )\n    scoring = {\"accuracy\": \"accuracy\", \"f1_macro\": \"f1_macro\"}\n    cv_results = cross_validate_with_multiple_metrics(X_use, y, lr, cv=cv, scoring=scoring, random_state=random_state)\n    lr.fit(X_use, y)\n    val_metrics = None\n    if Xv_use is not None and y_val is not None:\n        y_pred = lr.predict(Xv_use)\n        val_metrics = get_classification_metrics(y_val, y_pred, labels=target_labels)\n    return {\n        \"model_name\": \"LogisticRegression\",\n        \"estimator\": lr if return_estimator else None,\n        \"cv_scores\": cv_results[\"cv_scores\"],\n        \"mean_scores\": cv_results[\"mean_scores\"],\n        \"std_scores\": cv_results[\"std_scores\"],\n        \"val_metrics\": val_metrics,\n        \"n_features\": X_use.shape[1],\n        \"n_samples\": X_use.shape[0],\n    }\n\n\ndef fit_and_evaluate_random_forest(\n    X: pd.DataFrame,\n    y: pd.Series,\n    X_val: Optional[pd.DataFrame] = None,\n    y_val: Optional[pd.Series] = None,\n    *,\n    feature_cols: Optional[List[str]] = None,\n    target_labels: Optional[List[str]] = None,\n    cv: int = 5,\n    n_estimators: int = 100,\n    max_depth: Optional[int] = None,\n    random_state: Optional[int] = None,\n    return_estimator: bool = True,\n) -> Dict[str, Any]:\n    \"\"\"\n    Trains and evaluates a Random Forest classifier with cross-validation.\n\n    Args:\n        X (pd.DataFrame): Training features.\n        y (pd.Series): Training labels.\n        X_val (pd.DataFrame, optional): Validation features.\n        y_val (pd.Series, optional): Validation labels.\n        feature_cols (List[str], optional): Subset of features to use. If None, use all.\n        target_labels (List[str], optional): List of class labels (for metrics).\n        cv (int): Number of CV folds.\n        n_estimators (int): Number of trees.\n        max_depth (int, optional): Max tree depth.\n        random_state (int, optional): Seed.\n        return_estimator (bool): If True, return fitted estimator.\n\n    Returns:\n        Dict[str, Any]: Results including fitted model, CV metrics, and val metrics.\n\n    Raises:\n        ValueError: If data is invalid.\n\n    Return schema:\n        {\n            'model_name': str,\n            'estimator': RandomForestClassifier,\n            'cv_scores': Dict[str, List[float]],\n            'mean_scores': Dict[str, float],\n            'std_scores': Dict[str, float],\n            'val_metrics': Dict[str, Any] or None,\n            'n_features': int,\n            'n_samples': int,\n        }\n\n    Example:\n        results = fit_and_evaluate_random_forest(X, y, X_val, y_val, feature_cols=col_list)\n    \"\"\"\n    if feature_cols is not None:\n        X_use = X[feature_cols]\n        Xv_use = X_val[feature_cols] if X_val is not None else None\n    else:\n        X_use = X.copy()\n        Xv_use = X_val.copy() if X_val is not None else None\n\n    rf = RandomForestClassifier(\n        n_estimators=n_estimators,\n        max_depth=max_depth,\n        random_state=random_state,\n        n_jobs=-1,\n    )\n    scoring = {\"accuracy\": \"accuracy\", \"f1_macro\": \"f1_macro\"}\n    cv_results = cross_validate_with_multiple_metrics(X_use, y, rf, cv=cv, scoring=scoring, random_state=random_state)\n    rf.fit(X_use, y)\n    val_metrics = None\n    if Xv_use is not None and y_val is not None:\n        y_pred = rf.predict(Xv_use)\n        val_metrics = get_classification_metrics(y_val, y_pred, labels=target_labels)\n    return {\n        \"model_name\": \"RandomForestClassifier\",\n        \"estimator\": rf if return_estimator else None,\n        \"cv_scores\": cv_results[\"cv_scores\"],\n        \"mean_scores\": cv_results[\"mean_scores\"],\n        \"std_scores\": cv_results[\"std_scores\"],\n        \"val_metrics\": val_metrics,\n        \"n_features\": X_use.shape[1],\n        \"n_samples\": X_use.shape[0],\n    }\n\n\ndef fit_and_evaluate_svc(\n    X: pd.DataFrame,\n    y: pd.Series,\n    X_val: Optional[pd.DataFrame] = None,\n    y_val: Optional[pd.Series] = None,\n    *,\n    feature_cols: Optional[List[str]] = None,\n    target_labels: Optional[List[str]] = None,\n    cv: int = 5,\n    kernel: str = \"rbf\",\n    C: float = 1.0,\n    gamma: Union[str, float] = \"scale\",\n    random_state: Optional[int] = None,\n    return_estimator: bool = True,\n) -> Dict[str, Any]:\n    \"\"\"\n    Trains and evaluates a Support Vector Classifier (SVC) with cross-validation.\n\n    Args:\n        X (pd.DataFrame): Training features.\n        y (pd.Series): Training labels.\n        X_val (pd.DataFrame, optional): Validation features.\n        y_val (pd.Series, optional): Validation labels.\n        feature_cols (List[str], optional): Subset of features to use. If None, use all.\n        target_labels (List[str], optional): List of class labels (for metrics).\n        cv (int): Number of CV folds.\n        kernel (str): SVC kernel type.\n        C (float): Regularization parameter.\n        gamma (str or float): Kernel coefficient.\n        random_state (int, optional): Seed (for shuffling).\n        return_estimator (bool): If True, return fitted estimator.\n\n    Returns:\n        Dict[str, Any]: Results including fitted model, CV metrics, and val metrics.\n\n    Raises:\n        ValueError: If data is invalid.\n\n    Return schema:\n        {\n            'model_name': str,\n            'estimator': SVC,\n            'cv_scores': Dict[str, List[float]],\n            'mean_scores': Dict[str, float],\n            'std_scores': Dict[str, float],\n            'val_metrics': Dict[str, Any] or None,\n            'n_features': int,\n            'n_samples': int,\n        }\n\n    Example:\n        results = fit_and_evaluate_svc(X, y, X_val, y_val, feature_cols=col_list)\n    \"\"\"\n    if feature_cols is not None:\n        X_use = X[feature_cols]\n        Xv_use = X_val[feature_cols] if X_val is not None else None\n    else:\n        X_use = X.copy()\n        Xv_use = X_val.copy() if X_val is not None else None\n\n    svc = SVC(\n        kernel=kernel,\n        C=C,\n        gamma=gamma,\n        probability=True,  # For probability outputs if needed\n        random_state=random_state,\n    )\n    scoring = {\"accuracy\": \"accuracy\", \"f1_macro\": \"f1_macro\"}\n    cv_results = cross_validate_with_multiple_metrics(X_use, y, svc, cv=cv, scoring=scoring, random_state=random_state)\n    svc.fit(X_use, y)\n    val_metrics = None\n    if Xv_use is not None and y_val is not None:\n        y_pred = svc.predict(Xv_use)\n        val_metrics = get_classification_metrics(y_val, y_pred, labels=target_labels)\n    return {\n        \"model_name\": \"SVC\",\n        \"estimator\": svc if return_estimator else None,\n        \"cv_scores\": cv_results[\"cv_scores\"],\n        \"mean_scores\": cv_results[\"mean_scores\"],\n        \"std_scores\": cv_results[\"std_scores\"],\n        \"val_metrics\": val_metrics,\n        \"n_features\": X_use.shape[1],\n        \"n_samples\": X_use.shape[0],\n    }\n\n\n####################################\n# UTILITY: ENSEMBLING AND WRAPPING #\n####################################\n\ndef soft_voting_ensemble_predict(\n    estimators: List[Any],\n    X: pd.DataFrame,\n    class_labels: List[str],\n    weights: Optional[List[float]] = None,\n) -> np.ndarray:\n    \"\"\"\n    Makes ensemble predictions using soft voting (average predicted probabilities).\n\n    Args:\n        estimators (List[sklearn estimator]): List of fitted estimators with predict_proba().\n        X (pd.DataFrame): Data to predict on.\n        class_labels (List[str]): List of class labels (in order).\n        weights (List[float], optional): List of ensemble weights. If None, use equal weights.\n\n    Returns:\n        np.ndarray: Array of predicted class labels.\n\n    Raises:\n        ValueError: If any estimator lacks predict_proba, or weights mismatch.\n\n    Return schema:\n        np.ndarray of shape (n_samples,) with predicted class labels.\n\n    Example:\n        preds = soft_voting_ensemble_predict([lr, rf, svc], X_test, class_labels)\n    \"\"\"\n    n_estimators = len(estimators)\n    if n_estimators == 0:\n        raise ValueError(\"Must provide at least one estimator.\")\n    if weights is None:\n        weights = [1.0] * n_estimators\n    if len(weights) != n_estimators:\n        raise ValueError(\"Length of weights must match number of estimators.\")\n    probas = None\n    for est, w in zip(estimators, weights):\n        if not hasattr(est, \"predict_proba\"):\n            raise ValueError(\"All estimators must implement predict_proba.\")\n        p = est.predict_proba(X)\n        if probas is None:\n            probas = np.zeros_like(p, dtype=float)\n        probas += w * p\n    probas /= np.sum(weights)\n    preds = obesity_prediction_calibrator(probas, class_labels, method=\"argmax\")\n    return preds\n\n\n#####################\n# END OF MODULE     #\n#####################\n```"
    },
    {
        "role": "user",
        "content": "\n## TASK: CONVERT PYTHON TOOLS TO MARKDOWN DOCS ##\n\nYou will receive a complete Python module containing multiple tool functions.\n\nRules:\n- Use the function name as the tool name\n- Derive parameter info and types from the function signature and docstring\n- Keep the formatting EXACT (labels, backticks, enums, separators) per the spec\n- Output ONLY one concatenated fenced block: ```markdown\\n...sections...\\n```\n- Do not include any prose before or after the fenced block.\n- If a function is dataset-specific, include a note line in the Notes section starting with \"- Domain rationale:\" that briefly explains why the tool is suited to this dataset/competition\n\n\nFor EACH top-level function, produce a markdown section that follows the EXACT format of the example below.\n\nHere is the MARKDOWN format you should follow (example):\n```markdown\n## fill_missing_values\n\n**Name:** fill_missing_values  \n**Description:** Fill missing values in specified columns of a DataFrame. This tool can handle both numerical and categorical features by using different filling methods.  \n**Applicable Situations:** handle missing values in various types of features\n\n**Parameters:**\n- `data`:\n  - **Type:** `pd.DataFrame`\n  - **Description:** A pandas DataFrame object representing the dataset.\n- `columns`:\n  - **Type:** ``string` | `array``\n  - **Description:** The name(s) of the column(s) where missing values should be filled.\n- `method`:\n  - **Type:** `string`\n  - **Description:** The method to use for filling missing values.\n  - **Enum:** `auto` | `mean` | `median` | `mode` | `constant`\n  - **Default:** `auto`\n- `fill_value`:\n  - **Type:** ``number` | `string` | `null``\n  - **Description:** The value to use when method is 'constant'.\n  - **Default:** `None`\n\n**Required:** `data`, `columns`  \n**Result:** Successfully fill missing values in the specified column(s) of data  \n**Notes:**\n- The 'auto' method uses mean for numeric columns and mode for non-numeric columns.\n- Using 'mean' or 'median' on non-numeric columns will raise an error.\n- The 'mode' method uses the most frequent value, which may not always be appropriate.\n- Filling missing values can introduce bias, especially if the data is not missing completely at random.\n- Consider the impact of filling missing values on your analysis and model performance.\n\n---\n```\n\nPYTHON MODULE SOURCE:\n{python_source}\n"
    },
    {
        "role": "assistant",
        "content": "```markdown\n## cross_validate_with_multiple_metrics\n\n**Name:** cross_validate_with_multiple_metrics  \n**Description:** Performs cross-validation using multiple metrics and returns the mean and standard deviation for each metric.  \n**Applicable Situations:** Comparing model performance across several metrics using cross-validation.\n\n**Parameters:**\n- `X`:\n  - **Type:** `pd.DataFrame`\n  - **Description:** Feature matrix for model input.\n- `y`:\n  - **Type:** `pd.Series`\n  - **Description:** Target vector.\n- `estimator`:\n  - **Type:** estimator object\n  - **Description:** scikit-learn estimator to fit and evaluate.\n- `cv`:\n  - **Type:** `int`\n  - **Description:** Number of folds for cross-validation.\n  - **Default:** `5`\n- `scoring`:\n  - **Type:** `dict` | `None`\n  - **Description:** Dictionary of scoring metrics, e.g., `{'accuracy': 'accuracy', 'f1_macro': 'f1_macro'}`.\n  - **Default:** `None`\n- `random_state`:\n  - **Type:** `int` | `None`\n  - **Description:** Random seed for reproducibility.\n  - **Default:** `None`\n\n**Required:** `X`, `y`, `estimator`  \n**Result:** Dictionary containing cross-validation scores, means, and standard deviations for each metric  \n**Notes:**\n- Raises `ValueError` if X or y are empty or if their shapes mismatch.\n- The estimator is not fitted after running this function.\n- Metrics dictionary keys are the same as provided in the `scoring` argument.\n---\n## get_classification_metrics\n\n**Name:** get_classification_metrics  \n**Description:** Computes core classification metrics (accuracy, macro F1, confusion matrix, and classification report) for predictions.  \n**Applicable Situations:** Evaluating predictions on multiclass classification tasks.\n\n**Parameters:**\n- `y_true`:\n  - **Type:** `np.ndarray` | `pd.Series`\n  - **Description:** Ground truth target values.\n- `y_pred`:\n  - **Type:** `np.ndarray` | `pd.Series`\n  - **Description:** Predicted target values.\n- `labels`:\n  - **Type:** `list` | `None`\n  - **Description:** List of label names (optional, for consistent order).\n  - **Default:** `None`\n- `average`:\n  - **Type:** `str`\n  - **Description:** Averaging method for multi-class metrics.\n  - **Default:** `macro`\n\n**Required:** `y_true`, `y_pred`  \n**Result:** Dictionary containing accuracy, F1 macro, confusion matrix, and classification report  \n**Notes:**\n- Raises `ValueError` if input lengths mismatch.\n- The function uses the provided labels for metrics if given.\n---\n## obesity_grouped_stratified_kfold\n\n**Name:** obesity_grouped_stratified_kfold  \n**Description:** Returns a `StratifiedKFold` object, ensuring stratified folds for balanced class distribution among obesity risk levels. Ignores group_col and warns if provided, since group dependency is not present in this dataset.  \n**Applicable Situations:** Cross-validation in multiclass obesity classification with balanced class splits.\n\n**Parameters:**\n- `X`:\n  - **Type:** `pd.DataFrame`\n  - **Description:** Feature matrix.\n- `y`:\n  - **Type:** `pd.Series`\n  - **Description:** Target labels.\n- `group_col`:\n  - **Type:** `str` | `None`\n  - **Description:** Optional column for group-aware cross-validation (ignored).\n  - **Default:** `None`\n- `n_splits`:\n  - **Type:** `int`\n  - **Description:** Number of cross-validation folds.\n  - **Default:** `5`\n- `shuffle`:\n  - **Type:** `bool`\n  - **Description:** Whether to shuffle before splitting.\n  - **Default:** `True`\n- `random_state`:\n  - **Type:** `int` | `None`\n  - **Description:** Random seed.\n  - **Default:** `None`\n\n**Required:** `X`, `y`  \n**Result:** StratifiedKFold splitter object  \n**Notes:**\n- Raises `ValueError` if y is empty or n_splits < 2.\n- Warns if group_col is supplied; no group-dependent splits for this dataset.\n- Domain rationale: Obesity risk classification requires balanced class splits due to class imbalance risks; stratification by target is especially important in this competition.\n---\n## obesity_prediction_calibrator\n\n**Name:** obesity_prediction_calibrator  \n**Description:** Calibrates predicted class probabilities into final class labels for multi-class obesity classification, with optional tie-breaking methods.  \n**Applicable Situations:** Converting predicted probabilities (e.g., from softmax or predict_proba) to discrete class label predictions.\n\n**Parameters:**\n- `y_probs`:\n  - **Type:** `np.ndarray`\n  - **Description:** Array of predicted probabilities (shape: n_samples, n_classes).\n- `class_labels`:\n  - **Type:** `list`\n  - **Description:** List of class labels in the order of y_probs columns.\n- `method`:\n  - **Type:** `str`\n  - **Description:** Method to convert probabilities to labels.\n  - **Enum:** `argmax` | `top2_random`\n  - **Default:** `argmax`\n\n**Required:** `y_probs`, `class_labels`  \n**Result:** Numpy array of predicted class labels  \n**Notes:**\n- Raises `ValueError` if y_probs columns do not match number of class_labels, or if method is invalid.\n- 'argmax' assigns the class with the highest probability; 'top2_random' randomly selects among tied top probabilities.\n- Domain rationale: Obesity risk classes require precise mapping from probability to label, and this tool ensures competition-compliant prediction logic.\n---\n## obesity_submission_formatter\n\n**Name:** obesity_submission_formatter  \n**Description:** Formats predictions and IDs into the required Kaggle submission schema for the obesity_risks competition.  \n**Applicable Situations:** Preparing prediction outputs for submission, ensuring correct column order and naming.\n\n**Parameters:**\n- `ids`:\n  - **Type:** `pd.Series`\n  - **Description:** Series of IDs from the test set.\n- `preds`:\n  - **Type:** `np.ndarray` | `list`\n  - **Description:** Predicted class labels.\n- `id_col`:\n  - **Type:** `str`\n  - **Description:** Name for the ID column in the output.\n  - **Default:** `id`\n- `target_col`:\n  - **Type:** `str`\n  - **Description:** Name for the prediction/target column in the output.\n  - **Default:** `NObeyesdad`\n\n**Required:** `ids`, `preds`  \n**Result:** Submission-ready DataFrame with two columns  \n**Notes:**\n- Raises `ValueError` if lengths of ids and preds do not match.\n- Domain rationale: Ensures output format is fully compliant with the competition's submission requirements, reducing risk of format-based disqualification.\n---\n## fit_and_evaluate_logistic_regression\n\n**Name:** fit_and_evaluate_logistic_regression  \n**Description:** Trains and evaluates a Logistic Regression classifier with cross-validation, and (optionally) evaluates on a provided validation set. Returns standardized results for downstream comparison.  \n**Applicable Situations:** Comparing or benchmarking logistic regression models for multiclass classification.\n\n**Parameters:**\n- `X`:\n  - **Type:** `pd.DataFrame`\n  - **Description:** Training features.\n- `y`:\n  - **Type:** `pd.Series`\n  - **Description:** Training labels.\n- `X_val`:\n  - **Type:** `pd.DataFrame` | `None`\n  - **Description:** Validation features for out-of-sample evaluation.\n  - **Default:** `None`\n- `y_val`:\n  - **Type:** `pd.Series` | `None`\n  - **Description:** Validation labels.\n  - **Default:** `None`\n- `feature_cols`:\n  - **Type:** `list` | `None`\n  - **Description:** Subset of features to use; if None, use all.\n  - **Default:** `None`\n- `target_labels`:\n  - **Type:** `list` | `None`\n  - **Description:** List of all class labels for metrics/report.\n  - **Default:** `None`\n- `cv`:\n  - **Type:** `int`\n  - **Description:** Cross-validation folds.\n  - **Default:** `5`\n- `random_state`:\n  - **Type:** `int` | `None`\n  - **Description:** Seed.\n  - **Default:** `None`\n- `solver`:\n  - **Type:** `str`\n  - **Description:** Solver for LogisticRegression.\n  - **Default:** `liblinear`\n- `max_iter`:\n  - **Type:** `int`\n  - **Description:** Maximum iterations for LogisticRegression.\n  - **Default:** `500`\n- `return_estimator`:\n  - **Type:** `bool`\n  - **Description:** Whether to return the fitted estimator.\n  - **Default:** `True`\n\n**Required:** `X`, `y`  \n**Result:** Dictionary containing fitted estimator, CV metrics, optional validation metrics, and data shape info  \n**Notes:**\n- Raises `ValueError` if data is invalid or shapes mismatch.\n- Supports multiclass and binary targets.\n- Returned dictionary keys: model_name, estimator, cv_scores, mean_scores, std_scores, val_metrics, n_features, n_samples.\n---\n## fit_and_evaluate_random_forest\n\n**Name:** fit_and_evaluate_random_forest  \n**Description:** Trains and evaluates a Random Forest classifier with cross-validation, and (optionally) evaluates on a provided validation set. Returns standardized results for downstream comparison.  \n**Applicable Situations:** Comparing or benchmarking random forest models for multiclass classification.\n\n**Parameters:**\n- `X`:\n  - **Type:** `pd.DataFrame`\n  - **Description:** Training features.\n- `y`:\n  - **Type:** `pd.Series`\n  - **Description:** Training labels.\n- `X_val`:\n  - **Type:** `pd.DataFrame` | `None`\n  - **Description:** Validation features for out-of-sample evaluation.\n  - **Default:** `None`\n- `y_val`:\n  - **Type:** `pd.Series` | `None`\n  - **Description:** Validation labels.\n  - **Default:** `None`\n- `feature_cols`:\n  - **Type:** `list` | `None`\n  - **Description:** Subset of features to use; if None, use all.\n  - **Default:** `None`\n- `target_labels`:\n  - **Type:** `list` | `None`\n  - **Description:** List of all class labels for metrics/report.\n  - **Default:** `None`\n- `cv`:\n  - **Type:** `int`\n  - **Description:** Cross-validation folds.\n  - **Default:** `5`\n- `n_estimators`:\n  - **Type:** `int`\n  - **Description:** Number of trees.\n  - **Default:** `100`\n- `max_depth`:\n  - **Type:** `int` | `None`\n  - **Description:** Maximum tree depth.\n  - **Default:** `None`\n- `random_state`:\n  - **Type:** `int` | `None`\n  - **Description:** Seed.\n  - **Default:** `None`\n- `return_estimator`:\n  - **Type:** `bool`\n  - **Description:** Whether to return the fitted estimator.\n  - **Default:** `True`\n\n**Required:** `X`, `y`  \n**Result:** Dictionary containing fitted estimator, CV metrics, optional validation metrics, and data shape info  \n**Notes:**\n- Raises `ValueError` if data is invalid or shapes mismatch.\n- Returned dictionary keys: model_name, estimator, cv_scores, mean_scores, std_scores, val_metrics, n_features, n_samples.\n---\n## fit_and_evaluate_svc\n\n**Name:** fit_and_evaluate_svc  \n**Description:** Trains and evaluates a Support Vector Classifier (SVC) with cross-validation, and (optionally) evaluates on a provided validation set. Returns standardized results for downstream comparison.  \n**Applicable Situations:** Comparing or benchmarking SVC models for multiclass classification.\n\n**Parameters:**\n- `X`:\n  - **Type:** `pd.DataFrame`\n  - **Description:** Training features.\n- `y`:\n  - **Type:** `pd.Series`\n  - **Description:** Training labels.\n- `X_val`:\n  - **Type:** `pd.DataFrame` | `None`\n  - **Description:** Validation features for out-of-sample evaluation.\n  - **Default:** `None`\n- `y_val`:\n  - **Type:** `pd.Series` | `None`\n  - **Description:** Validation labels.\n  - **Default:** `None`\n- `feature_cols`:\n  - **Type:** `list` | `None`\n  - **Description:** Subset of features to use; if None, use all.\n  - **Default:** `None`\n- `target_labels`:\n  - **Type:** `list` | `None`\n  - **Description:** List of all class labels for metrics/report.\n  - **Default:** `None`\n- `cv`:\n  - **Type:** `int`\n  - **Description:** Cross-validation folds.\n  - **Default:** `5`\n- `kernel`:\n  - **Type:** `str`\n  - **Description:** SVC kernel type.\n  - **Default:** `rbf`\n- `C`:\n  - **Type:** `float`\n  - **Description:** Regularization parameter.\n  - **Default:** `1.0`\n- `gamma`:\n  - **Type:** `str` | `float`\n  - **Description:** Kernel coefficient.\n  - **Default:** `scale`\n- `random_state`:\n  - **Type:** `int` | `None`\n  - **Description:** Seed (used for shuffling).\n  - **Default:** `None`\n- `return_estimator`:\n  - **Type:** `bool`\n  - **Description:** Whether to return the fitted estimator.\n  - **Default:** `True`\n\n**Required:** `X`, `y`  \n**Result:** Dictionary containing fitted estimator, CV metrics, optional validation metrics, and data shape info  \n**Notes:**\n- Raises `ValueError` if data is invalid or shapes mismatch.\n- Returned dictionary keys: model_name, estimator, cv_scores, mean_scores, std_scores, val_metrics, n_features, n_samples.\n---\n## soft_voting_ensemble_predict\n\n**Name:** soft_voting_ensemble_predict  \n**Description:** Makes ensemble predictions by averaging predicted probabilities (soft voting) from multiple fitted estimators, then mapping to class labels.  \n**Applicable Situations:** Ensembling multiple probabilistic classifiers for multiclass predictions.\n\n**Parameters:**\n- `estimators`:\n  - **Type:** `list`\n  - **Description:** List of fitted estimators implementing `predict_proba`.\n- `X`:\n  - **Type:** `pd.DataFrame`\n  - **Description:** Data to predict on.\n- `class_labels`:\n  - **Type:** `list`\n  - **Description:** List of class labels, in order corresponding to predicted probabilities.\n- `weights`:\n  - **Type:** `list` | `None`\n  - **Description:** Ensemble weights for each estimator; if None, use equal weights.\n  - **Default:** `None`\n\n**Required:** `estimators`, `X`, `class_labels`  \n**Result:** Numpy array of predicted class labels  \n**Notes:**\n- Raises `ValueError` if any estimator lacks predict_proba, or if the number of weights does not match the number of estimators.\n- Uses obesity_prediction_calibrator to map ensemble probabilities to class labels.\n---\n```"
    }
]