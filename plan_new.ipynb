{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "5622bbaf",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "5e14f4fb",
   "metadata": {},
   "source": [
    "# Multi-Agent Pipeline Flow Summary Table\n",
    "\n",
    "| **State** | **Agents Created** | **Agent Responsibilities** | **Unit Tests?** | **Debugging?** | **Outcome / Transition Trigger** |\n",
    "|----------|--------------------|----------------------------|------------------|----------------|----------------------------------|\n",
    "| **1. Understand Background** | Reader → Reviewer → Summarizer | Reader extracts competition background → Reviewer checks format → Summarizer finalizes | ❌ None | ❌ No | JSON extracted → Move to Preliminary EDA |\n",
    "| **2. Preliminary EDA** | Planner → Developer → Reviewer → Summarizer | Planner creates EDA plan; Developer generates plots; Reviewer checks; Summarizer summarizes | ✔ Yes (image count) | ❌ No | All tests passed → Move to Data Cleaning |\n",
    "| **3. Data Cleaning** | Planner → Developer → Reviewer → Summarizer | Planner outlines cleaning; Developer writes cleaning code; Unit tests enforce data integrity | ✔ Extensive tests | ✔ Yes (missing Fare fixed) | All tests passed → Move to In-depth EDA |\n",
    "| **4. In-depth EDA** | Planner → Developer → Reviewer → Summarizer | Planner outlines deep EDA; Developer executes; Reviewer checks; Summarizer writes summary | ✔ Yes (image count) | ❌ No | All tests passed → Move to Feature Engineering |\n",
    "| **5. Feature Engineering** | Planner → Developer → Reviewer → Summarizer | Planner defines FE; Developer executes transformations; Reviewer checks output; Summarizer writes summary | ✔ Yes (columns, ID, target, feature explosion) | ❌ No | All tests passed → Move to Model Building |\n",
    "| **6. Model Building, Validation, Prediction** | Planner → Developer → Reviewer → Summarizer | Planner defines training; Developer trains model and produces submission.csv | ✔ Yes (submission format, column names, validity) | ✔ Yes (1st fail → debug → 2nd pass) | All tests passed → SOP completes |\n",
    "| **7. SOP Completed** | — | — | — | — | **Competition titanic SOP is completed** |\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f9e4587f",
   "metadata": {},
   "source": [
    "# Implementation\n",
    "\n",
    "The pipeline progresses by iterating through States (phases):\n",
    "\n",
    "- **State phases:**\n",
    "  - \"Understand Background\"\n",
    "  - \"Preliminary Exploratory Data Analysis\"\n",
    "  - \"Data Cleaning\"\n",
    "  - \"In-depth Exploratory Data Analysis\"\n",
    "  - \"Feature Engineering\"\n",
    "  - \"Model Building, Validation, and Prediction\"\n",
    "\n",
    "## Phase Execution\n",
    "\n",
    "1. Create a memory directory for each phase State.\n",
    "2. Iterate through each agent in that phase.\n",
    "3. Each agent returns a memory dict like `{ \"planner\": { ... } }` and calls `update_memory(memory)` to merge output into the current phase memory.\n",
    "\n",
    "## Memory Model\n",
    "\n",
    "- Each phase gets its own memory (not automatically shared with later phases).\n",
    "- Agents write to the phase memory dict, e.g.:\n",
    "\n",
    "```json\n",
    "{\n",
    "  \"reader\": {\n",
    "    \"history\": \"...\",\n",
    "    \"role\": \"Reader\",\n",
    "    \"description\": \"...\",\n",
    "    \"task\": \"...\",\n",
    "    \"input\": \"<background_info>...</background_info>\",\n",
    "    \"summary\": \"...\",\n",
    "    \"result\": \"...\"\n",
    "  },\n",
    "  \"planner\": {\n",
    "    \"history\": \"...\",\n",
    "    \"role\": \"Planner\",\n",
    "    \"description\": \"...\",\n",
    "    \"task\": \"...\",\n",
    "    \"input\": \"<background_info>...</background_info>\",\n",
    "    \"summary\": \"...\",\n",
    "    \"result\": \"...\"\n",
    "  },\n",
    "  \"reviewer\": {\n",
    "    \"history\": \"...\",\n",
    "    \"score\": 3,\n",
    "    \"suggestion\": \"...\",\n",
    "    \"result\": \"review text\"\n",
    "  }\n",
    "}\n",
    "```\n",
    "\n",
    "## Iterative Repeats (Low Score)\n",
    "\n",
    "When the phase score is low, the process repeats for a limited number of iterations: the score is determined the avarage of all the agents in the phase/ if developer did not run=0\n",
    "\n",
    "```python\n",
    "while not state.finished:\n",
    "    agent = <planner/developer/reviewer/summarizer>\n",
    "    agent.action(state)\n",
    "    state.update_memory(...)\n",
    "    state.next_step()\n",
    "\n",
    "if state.finished:\n",
    "    state.set_score()  # evaluate score\n",
    "\n",
    "if state.score < 3:\n",
    "    new_state = State(phase=old_phase)\n",
    "    new_state.memory = deepcopy(old_memory)\n",
    "```\n",
    "\n",
    "- Repeat re-runs the same phase with carried memory plus a fresh slot.\n",
    "- Success advances to the next phase and starts with a fresh memory unless explicitly copied."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "499df486",
   "metadata": {},
   "source": [
    "\n",
    "## The **Planner**\n",
    "1. Check if `state.memory` length > 1; evaluate score.\n",
    "2. Execution (4 rounds):\n",
    "\n",
    "   Round 0:\n",
    "   - Read data files in the phase and create a data preview summary.\n",
    "   - Set background info in state with the data preview.\n",
    "   - Get state info: phase guidelines and goals (from State class).\n",
    "   - Formulate the prompt so it is added to LLM history.\n",
    "\n",
    "   Round 1:\n",
    "   - Retrieve previous phases' PLAN and REPORT; read current data.\n",
    "   - Use READ tools (needs modification for new toolsmith outputs).\n",
    "   - Generate a new PLAN using previous plans, previous reports, current data, and tool documentation.\n",
    "\n",
    "   Round 2:\n",
    "   - Reorganize the plan into clean markdown structure.\n",
    "\n",
    "   Round 3:\n",
    "   - Convert final markdown plan into JSON schema (structured plan object).\n",
    "\n",
    "   Tool integration:\n",
    "   - Planner must reference tools generated by ToolSmith.\n",
    "   - Controlled via `agent_base._get_tools` resolution logic.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7b279144",
   "metadata": {},
   "source": [
    "\n",
    "## The **Agent_BASE**\n",
    "- Initialization: Stores role, description, model, construct the LLM instnace from  OPENAI\n",
    "- Memory/context helpers\n",
    "_gather_experience_with_suggestion(state): aggregates past agent outputs, reviewer feedback, and (for developer) error/not-pass info from files.\n",
    "- Data helpers: \n",
    "    - **NEEDUPDATE** _read_data(state, num_lines): reads sample rows from train/test/cleaned/processed CSVs depending on phase; extracts eval metric via LLM in model-building phase.\n",
    "    - _data_preview(state, num_lines): asks LLM to produce a preview using PROMPT_DATA_PREVIEW; writes data_preview.txt.\n",
    "    - **NEEDUPDATE** _get_feature_info(state): compares columns before/after a phase, infers target, returns a feature summary prompt string.\n",
    "    - **NEEDUPDATE** Tool retrieval：  **_get_tools(state)** -> (tools_text, tool_names): Loads phase→tool names from config.json.\n",
    "        - For developer in certain phases, extracts tool_names from the markdown plan via LLM; else uses config’s list.\n",
    "        - Builds a vector DB with OpenaiEmbeddings + RetrieveTool and queries tool docs by name.\n",
    "        - Returns a concatenated tools description string and the list of names; also writes tools_used_in_dir.md.\n",
    "        - RetrieveTool Class: **NEEDUPDATE**, Which is used by developer and planner\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b7a14ccd",
   "metadata": {},
   "source": [
    "## STATE.PY\n",
    "\n",
    "- Loads config (agents per phase, directories, unit tests, rules, allowed tools).\n",
    "- Resolves agents for the phase, directories, unit tests, rulebook parameters, and ml tool names.\n",
    "- Sets competition_dir, dir_name, restore_dir, ml_tools, background_info, context.\n",
    "- **NEEDUPDATE** get_state_info: phase-specific guidance text.\n",
    "- **CANUSE** set_background_info, get_current_agent.\n",
    "- generate_rules and _format_rules: writes user_rules.txt for the phase. **UPDATE CONFIG?**\n",
    "- set_score: Get score from reviewer **Potential UPDATE**\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "        "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "69e8abf4",
   "metadata": {},
   "source": [
    "# Plan\n",
    "\n",
    "OVERVIEW: \n",
    "1. Run the background understanding agent to read the data challenge and inspect its output.\n",
    "2. Call an agent to read that background output & Data and generate:\n",
    "   - A domain‑specific tool (Python function/module)\n",
    "   - A markdown file that documents the generated tool\n",
    "3. Refer the Developer and Planner agent to the generated tools\n",
    "    - Flow inside each phase: ToolSmith → Planner → Developer → Reviewer → Summarizer\n",
    "\n",
    "\n",
    "TODOs \n",
    "\n",
    "**(config.json)**:\n",
    "- Add  Toolsmith agent to config.json under phase_to_agents for the phases where it should run first.  \n",
    "    - Update `phase_to_agents` to include the ToolSmith agent.\n",
    "    - Update `phase_to_ml_tools` to point to generated tools.\n",
    "    - Update `rulebook_parameters` to reflect generated tools.\n",
    "\n",
    "**(STATE.PY)**:\n",
    "- Ensure Toolsmith writes multi_agents/function_to_schema.json; then call state.reload_function_registry() before Developer/Planner use tools.\n",
    "- Constructor Parameters: phase str, competiton str, message str\n",
    "- Attributes: \n",
    "    - phase, competition, message\n",
    "    - **memory:(List[Dict[str, Any]]): History of agent actions/results (starts with [{}])**; \n",
    "    - current_step int to track which agent; \n",
    "    - score: Set by the Reviewer Agent at the end of each state (Iterated through every agent)\n",
    "\n",
    "**(Agent_BASE)**\n",
    "- See above\n",
    "\n",
    "\n",
    "\n",
    "#### Optionally generate unit tests to validate new tools.\n",
    "\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "AutoKaggle",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "name": "python",
   "version": "3.11.14"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
